{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# [MLP_enhance] BatchNorm & Dropoutì„ í†µí•œ ê°œì„ \n",
                "- **Previous (MLP_base)**: ì„±ëŠ¥ì€ ì¢‹ì€ë°, ì¬ìˆ˜ ì—†ìœ¼ë©´ í•™ìŠµì´ ë§í•  ê²ƒ ê°™ì´ ìœ„íƒœë¡œì› ë‹¤.\n",
                "- **Analysis**: ì¸µì„ ì§€ë‚  ë•Œë§ˆë‹¤ ë°ì´í„° ë¶„í¬ê°€ ì ë¦¬ëŠ” í˜„ìƒ(Internal Covariate Shift) ë•Œë¬¸ì¼ ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  íŠ¹ì • íŠ¹ì§•ì—ë§Œ ë„ˆë¬´ ì˜ì¡´í•˜ëŠ”(Overfitting) ê²½í–¥ë„ ë³´ì¸ë‹¤.\n",
                "- **Solution**: í˜„ì—…ì—ì„œ ì“°ëŠ” 'ì¹˜íŠ¸í‚¤' 2ê°œë¥¼ ë„ì…í•œë‹¤.\n",
                "    1. **Batch Norm**: ë°ì´í„°ì˜ ì¤‘ì‹¬ì„ ê°•ì œë¡œ ë§ì¶°ì¤€ë‹¤.\n",
                "    2. **Dropout**: ì¼ë¶€ ë‰´ëŸ°ì„ ê°•ì œë¡œ ë„ê³  ê³µë¶€ì‹œì¼œ ì‘ìš©ë ¥ì„ í‚¤ìš´ë‹¤.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ (Libraries)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 46,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. íŒŒì´ì¬ ê¸°ë³¸ ë„êµ¬ (ì‹œìŠ¤í…œ ê´€ë ¨)\n",
                "import sys # íŒŒì´ì¬ ì‹œìŠ¤í…œ(System)ì„ ê±´ë“œë¦¬ëŠ” ë„êµ¬\n",
                "import os  # ì»´í“¨í„° ìš´ì˜ì²´ì œ(OS, í´ë” ê²½ë¡œ ë“±)ë¥¼ ë‹¤ë£¨ëŠ” ë„êµ¬\n",
                "\n",
                "# 2. ë°ì´í„° ë‹¤ë£¨ëŠ” ë„êµ¬ (ì—‘ì…€, ê³„ì‚°ê¸°)\n",
                "import pandas as pd  # 'í‘œ(Table)'ë¥¼ ë‹¤ë£¨ëŠ” ì—‘ì…€ ê°™ì€ ë„êµ¬\n",
                "import numpy as np   # 'ìˆ«ì(Number)' ê³„ì‚°ì„ ì—„ì²­ ë¹ ë¥´ê²Œ í•˜ëŠ” ë„êµ¬\n",
                "\n",
                "# 3. ë”¥ëŸ¬ë‹ ë„êµ¬ (PyTorch)\n",
                "import torch\n",
                "import torch.nn as nn        # ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ 'ì¸µ(Layer)'ì„ ë§Œë“œëŠ” ë„êµ¬\n",
                "import torch.optim as optim  # ëª¨ë¸ì„ 'í•™ìŠµ(Train)'ì‹œí‚¤ëŠ” ìµœì í™” ë„êµ¬\n",
                "from torch.utils.data import DataLoader, TensorDataset  # ë°ì´í„°ë¥¼ 'ë°°ì¹˜(Batch)' ë‹¨ìœ„ë¡œ ë¬¶ëŠ” ë„êµ¬\n",
                "\n",
                "# 4. ë¨¸ì‹ ëŸ¬ë‹ ë„êµ¬ (Scikit-learn)\n",
                "from sklearn.model_selection import train_test_split  # ë°ì´í„°ë¥¼ í•™ìŠµìš©/ì‹œí—˜ìš©ìœ¼ë¡œ ë‚˜ëˆ„ëŠ” ë„êµ¬\n",
                "from sklearn.preprocessing import StandardScaler  # ë°ì´í„° ë²”ìœ„ë¥¼ ì¼ì •í•˜ê²Œ ë§ì¶”ëŠ” ë„êµ¬ (ìŠ¤ì¼€ì¼ë§)\n",
                "from imblearn.over_sampling import SMOTE  # ë¶ˆê· í˜•í•œ ë°ì´í„° ë¹„ìœ¨ì„ ë§ì¶°ì£¼ëŠ” ë„êµ¬ (ì˜¤ë²„ìƒ˜í”Œë§)\n",
                "\n",
                "# 5. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Optuna)\n",
                "import optuna\n",
                "\n",
                "# 5. í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •\n",
                "# í˜„ì¬ ìœ„ì¹˜(notebooks/dl)ì—ì„œ ë‘ ë‹¨ê³„ ìƒìœ„('../../')ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¡œ ì¸ì‹ì‹œí‚´\n",
                "sys.path.append(os.path.abspath('../../'))\n",
                "\n",
                "# 6. ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ (ìš°ë¦¬ê°€ ë§Œë“  ì½”ë“œ)\n",
                "from models.model_definitions import MLP_enhance  # ëª¨ë¸ ì„¤ê³„ë„ ê°€ì ¸ì˜¤ê¸°\n",
                "from app.utils.metrics import evaluate_churn_metrics  # í‰ê°€ ì§€í‘œ ê³„ì‚°ê¸° ê°€ì ¸ì˜¤ê¸°\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ë°ì´í„° íŒŒì´í”„ë¼ì¸ ìœ ì§€\n",
                "- **ì›ì¹™**: DL1ê³¼ ë°ì´í„°ëŠ” **100% ë™ì¼**í•´ì•¼ í•œë‹¤.\n",
                "- **ì´ìœ **: ê·¸ë˜ì•¼ \"ëª¨ë¸ì„ ë°”ê¿”ì„œ ì„±ëŠ¥ì´ ì¢‹ì•„ì§„ ê±´ì§€\", \"ë°ì´í„°ê°€ ë°”ë€ ê±´ì§€\" í—·ê°ˆë¦¬ì§€ ì•ŠëŠ”ë‹¤. ê³¼í•™ì  ì‹¤í—˜ì˜ ê¸°ë³¸(Control Variable)ì´ë‹¤."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ (Data Load & Transformation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 47,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ë¡œë”©ì¤‘~\n"
                    ]
                }
            ],
            "source": [
                "# 1. ë¡œë”© ì‹œì‘ ë©”ì‹œì§€\n",
                "print('ë¡œë”©ì¤‘~')\n",
                "\n",
                "# 2. ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
                "# ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì €ì¥ëœ í´ë” ìœ„ì¹˜\n",
                "base_path = \"/Users/gimdabin/SKN23-2nd-3Team/data/processed/\"\n",
                "\n",
                "# 3. Parquet íŒŒì¼ ì½ê¸° (CSVë³´ë‹¤ ë¹ ë¥´ê³  ê°€ë²¼ì›€)\n",
                "anchors = pd.read_parquet(base_path + \"anchors.parquet\")            # ê¸°ì¤€ì  (ëˆ„ê°€, ì–¸ì œ)\n",
                "features = pd.read_parquet(base_path + \"features_ml_clean.parquet\") # íŠ¹ì§• (ë¬´ì—‡ì„ í–ˆë‚˜)\n",
                "labels = pd.read_parquet(base_path + \"labels.parquet\")              # ì •ë‹µ (ì´íƒˆí–ˆë‚˜?)\n",
                "\n",
                "# 4. ID ì»¬ëŸ¼ í˜•ì‹ í†µì¼\n",
                "# ìˆ«ìì™€ ë¬¸ìê°€ ì„ì´ì§€ ì•Šë„ë¡ ëª¨ë‘ ë¬¸ìì—´(string)ë¡œ ë³€í™˜\n",
                "anchors['user_id'] = anchors['user_id'].astype(str)\n",
                "features['user_id'] = features['user_id'].astype(str)\n",
                "labels['user_id'] = labels['user_id'].astype(str)\n",
                "\n",
                "# 5. ë°ì´í„° ë³‘í•© (Merge)\n",
                "# ì„¸ ê°œì˜ í…Œì´ë¸”ì„ 'user_id'ì™€ 'anchor_time' ê¸°ì¤€ìœ¼ë¡œ í•˜ë‚˜ë¡œ í•©ì¹¨\n",
                "data = anchors.merge(features, on=['user_id', 'anchor_time'], how='inner')\n",
                "data = data.merge(labels, on=['user_id', 'anchor_time'], how='inner')\n",
                "\n",
                "# 6. íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (Target)\n",
                "# labelì´ 'm2'(ì´íƒˆ)ë©´ 1, ì•„ë‹ˆë©´ 0ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì»´í“¨í„°ê°€ ì´í•´í•˜ë„ë¡ í•¨\n",
                "data['target'] = (data['label'] == 'm2').astype(int)\n",
                "\n",
                "# 7. íŠ¹ì§•(Feature)ê³¼ ì •ë‹µ(Label) ë¶„ë¦¬\n",
                "# í•™ìŠµì— ë°©í•´ë˜ëŠ” ì‹ë³„ì(ID, ì‹œê°„)ëŠ” ì œê±° -> ê³¼ì í•© ë°©ì§€\n",
                "# ëˆ„êµ¬ëƒëŠ” ì¤‘ìš”í•˜ì§€ì•Šê³  ê³µë¶€ë¥¼ ì–¼ë§ˆë‚˜ í–ˆëƒë¥¼ ë³´ê³  íŒë‹¨í•˜ë„ë¡, ë‚ ì§œì— ë”°ë¼ì„œ ì´ìƒí•œ ê·œì¹™ì„ ë§Œë“¤ì§€ ì•Šë„ë¡\n",
                "feature_cols = [c for c in features.columns if c not in ['user_id', 'anchor_time']]\n",
                "X = data[feature_cols].copy().fillna(0)  # ë¹ˆ ê°’(NaN)ì€ 0ìœ¼ë¡œ ì±„ì›€\n",
                "y = data['target'].values                # ì •ë‹µ ê°’ë§Œ ì¶”ì¶œ\n",
                "\n",
                "# 8. ë°ì´í„° ë‚˜ëˆ„ê¸° (Train/Val/Test Split)\n",
                "# ì „ì²´ ë°ì´í„°ë¥¼ 6:2:2 ë¹„ìœ¨ë¡œ ë‚˜ëˆ” (stratify=y: ì •ë‹µ ë¹„ìœ¨ ìœ ì§€)\n",
                "X_train, X_temp, y_train, y_temp = train_test_split(\n",
                "    X, y,\n",
                "    test_size=0.4,   # í…ŒìŠ¤íŠ¸ ë°ì´í„° 40%\n",
                "    random_state=42, # ëœë¤ ì‹œë“œ ì„¤ì • (ì¬í˜„ ê°€ëŠ¥)\n",
                "    stratify=y       # ì •ë‹µ ë¹„ìœ¨ ìœ ì§€\n",
                ")\n",
                "X_val, X_test, y_val, y_test = train_test_split(\n",
                "    X_temp, y_temp,\n",
                "    test_size=0.5,   # ê²€ì¦ ë°ì´í„° 50%\n",
                "    random_state=42, # ëœë¤ ì‹œë“œ ì„¤ì • (ì¬í˜„ ê°€ëŠ¥)\n",
                "    stratify=y_temp   # ì •ë‹µ ë¹„ìœ¨ ìœ ì§€\n",
                ")\n",
                "\n",
                "# 9. ë°ì´í„° ë¶ˆê· í˜• í•´ì†Œ (SMOTE)\n",
                "# ì´íƒˆ ë°ì´í„°(ì†Œìˆ˜)ë¥¼ ë³µì œí•˜ì—¬ 1:1 ë¹„ìœ¨ë¡œ ë§ì¶¤ (í•™ìŠµ ë°ì´í„°ì—ë§Œ ì ìš©)\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
                "\n",
                "# 10. ìŠ¤ì¼€ì¼ë§ (Scaling)\n",
                "# ê°’ì˜ ë²”ìœ„ë¥¼ ë¹„ìŠ·í•˜ê²Œ ë§ì¶¤ (ì˜ˆ: 0~1 ì‚¬ì´, ë˜ëŠ” í‰ê·  0)\n",
                "scaler = StandardScaler() \n",
                "X_train_scaled = scaler.fit_transform(X_train_res) # ê¸°ì¤€ì ì„ í•™ìŠµë°ì´í„°ë¡œ ì„¤ì • í›„ Numpyë°°ì—´ë¡œ ë³€í™˜\n",
                "X_val_scaled = scaler.transform(X_val)             # ê²€ì¦ ë°ì´í„° Numpyë°°ì—´ë¡œ ë³€í™˜\n",
                "X_test_scaled = scaler.transform(X_test)           # í…ŒìŠ¤íŠ¸ ë°ì´í„° Numpyë°°ì—´ë¡œ ë³€í™˜\n",
                "\n",
                "# 11. ë°ì´í„°ë¡œë” ìƒì„± (DataLoader)\n",
                "# ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ë°ì´í„°ë¥¼ ì¡°ê¸ˆì”©(Batch) ë¨¹ì—¬ì£¼ê¸° ìœ„í•œ í¬ì¥ ì‘ì—…\n",
                "train_loader = DataLoader(\n",
                "    TensorDataset(\n",
                "        torch.FloatTensor(X_train_scaled), # Numpyë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
                "        torch.FloatTensor(y_train_res)     # Numpyë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
                "        ), batch_size=256, shuffle=True)   # batch_size: í•œ ë²ˆì— ì²˜ë¦¬í•  ë°ì´í„°ì˜ í¬ê¸°, shuffle: ë°ì´í„°ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ìŒ\n",
                "val_loader = DataLoader(\n",
                "    TensorDataset(\n",
                "        torch.FloatTensor(X_val_scaled),   # Numpyë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
                "        torch.FloatTensor(y_val)           # Numpyë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
                "        ), batch_size=256)\n",
                "test_loader = DataLoader(\n",
                "    TensorDataset(\n",
                "        torch.FloatTensor(X_test_scaled),  # Numpyë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
                "        torch.FloatTensor(y_test)          # Numpyë°°ì—´ì„ PyTorch í…ì„œë¡œ ë³€í™˜\n",
                "        ), batch_size=256)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Train, Val, Testë¡œ ë‚˜ëˆˆ ì´ìœ  -> ê³¼ì í•©ë°©ì§€\n",
                "    - Train (í•™ìŠµ ë°ì´í„°): êµê³¼ì„œ. ì—´ì‹¬íˆ ê³µë¶€í•´ì„œ ì§€ì‹ì„ ìŒ“ëŠ” ìš©ë„.\n",
                "    - Val (ê²€ì¦ ë°ì´í„°): ëª¨ì˜ê³ ì‚¬. ê³µë¶€í•˜ëŠ” ë„ì¤‘ì— \"ë‚´ê°€ ì˜í•˜ê³  ìˆë‚˜?\" ìˆ˜ì‹œë¡œ ì²´í¬í•˜ê³ , ê³µë¶€ ë°©í–¥(í•˜ì´í¼íŒŒë¼ë¯¸í„°)ì„ ê³ ì¹˜ëŠ” ìš©ë„.\n",
                "    - Test (í…ŒìŠ¤íŠ¸ ë°ì´í„°): ìˆ˜ëŠ¥(ìµœì¢… ì‹œí—˜). í•™ìŠµì´ ë‹¤ ëë‚˜ê³  ë‚˜ì„œ ë”± í•œ ë²ˆë§Œ ì‹¤ë ¥ì„ ê²€ì¦í•˜ëŠ” ìš©ë„.\n",
                "        - train -> val -> test ìˆœìœ¼ë¡œ testë¥¼ ëê¹Œì§€ ìˆ¨ê²¨ì„œ ê³¼ì í•©ì„ ë°©ì§€\n",
                "\n",
                "- train 60%, val 20%, test 20%ë¡œ ë¶„ë¦¬\n",
                "\n",
                "- FloatTensor ì˜ ì´ìœ \n",
                "    - scaler.fit_transform( )ì„ ì‹¤í–‰í•˜ë©´, ì‚¬ì´í‚·ëŸ°(Scikit-learn)ì´ ë°ì´í„°ë¥¼ ë³€í™˜í•œ ë’¤ ìë™ìœ¼ë¡œ ë„˜íŒŒì´ ë°°ì—´(Numpy Array) í˜•íƒœë¡œ ë±‰ì–´ëƒ„\n",
                "    - ì´ numpyë°°ì—´ì„ pytorchëŠ” ì´í•´í•  ìˆ˜ ì—†ìœ¼ë‹ˆ FloatTensorí˜•íƒœë¡œ ë³€í™˜í•˜ëŠ”ê²ƒ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ‘¨â€ğŸ’» Developer's Log: êµ¬ì¡° ê°œì„  (Stabilization)\n",
                "- **ë³€ê²½ì **: `Linear` ë‹¤ìŒì— ë°”ë¡œ `ReLU`ë¥¼ ì“°ë˜ DL1ê³¼ ë‹¬ë¦¬, `Linear -> BN -> ReLU -> Dropout` ìˆœì„œë¡œ ë¸”ë¡ì„ ì§°ë‹¤.\n",
                "- **ê¸°ëŒ€íš¨ê³¼**:\n",
                "    1. **BN**: í•™ìŠµì´ ë¹¨ë¼ì§€ê³ , Loss ê³¡ì„ ì´ ì˜ˆì˜ê²Œ ë–¨ì–´ì§ˆ ê²ƒì´ë‹¤.\n",
                "    2. **Dropout**: Training ì ìˆ˜ì™€ Test ì ìˆ˜ ì°¨ì´(Gap)ê°€ ì¤„ì–´ë“¤ ê²ƒì´ë‹¤. (Overfitting ë°©ì§€)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Optunaë¥¼ í™œìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (Hyperparameter Tuning)\n",
                "- ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ê¸° ìœ„í•´ ìµœì ì˜ í•˜ì´í¼íŒŒë¼ë¯¸í„°(LR, Hidden Dim, Dropout ë“±)ë¥¼ ì°¾ìŠµë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ‘¨â€ğŸ’» Developer's Log: ìŠ¤ë§ˆíŠ¸í•œ íŠœë‹ ì „ëµ (Efficiency & Accuracy)\n",
                "- **ê³ ë¯¼**: ëª¨ë“  íŒŒë¼ë¯¸í„°ë¥¼ ë‹¤ íŠœë‹í•˜ê³  ì‹¶ì§€ë§Œ, ë¬´ì‘ì • ëŒë¦¬ë©´ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦°ë‹¤.\n",
                "- **í•´ê²°ì±…**: **'TPE Sampler'**ì™€ **'Hyperband Pruner'**ì˜ ì¡°í•©.\n",
                "    1. **TPE (Tree-structured Parzen Estimator)**: ë©ì²­í•˜ê²Œ ëœë¤ìœ¼ë¡œ ì°¾ëŠ” ê²Œ ì•„ë‹ˆë¼, 'ì´ì „ì— ì˜ ë‚˜ì™”ë˜ ì„¤ì •'ì„ ì°¸ê³ í•´ì„œ ë” ë˜‘ë˜‘í•˜ê²Œ ì°ëŠ”ë‹¤.\n",
                "    2. **Hyperband Pruner (ê°€ì§€ì¹˜ê¸°)**: ê°€ë§ ì—†ëŠ” ì‹œë„ëŠ” ì´ˆë°˜ì— ê³¼ê°í•˜ê²Œ ì˜ë¼ë‚¸ë‹¤(Early Stopping). ìì› ë‚­ë¹„ë¥¼ ìµœì†Œí™”í•œë‹¤.\n",
                "- **ëª©í‘œ**: ìµœì†Œí•œì˜ ì‹œê°„ìœ¼ë¡œ ìµœëŒ€í•œ ê¼¼ê¼¼í•˜ê²Œ(Thorough) ìµœì ì˜ ì¡°í•©ì„ ì°¾ì•„ë‚¸ë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 48,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2026-01-12 16:10:44,824] A new study created in memory with name: no-name-36ba1344-1b60-48e5-ba84-e9e8d317b567\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ğŸš€ [Smart Tuning] ì´ˆê³ ì†/ì´ˆì •ë°€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘... (TPE + Hyperband)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[I 2026-01-12 16:12:56,904] Trial 0 finished with value: 0.6322586934708949 and parameters: {'lr': 0.0005611516415334506, 'weight_decay': 0.0007969454818643932, 'hidden_dim': 64, 'dropout_rate': 0.12323344486727979, 'epochs': 18, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 0 with value: 0.6322586934708949.\n",
                        "[I 2026-01-12 16:14:29,368] Trial 1 finished with value: 0.625309261229803 and parameters: {'lr': 0.0004059611610484307, 'weight_decay': 0.00011207606211860574, 'hidden_dim': 256, 'dropout_rate': 0.21685785941408728, 'epochs': 10, 'activation': 'leaky_relu', 'optimizer': 'SGD'}. Best is trial 1 with value: 0.625309261229803.\n",
                        "[I 2026-01-12 16:14:46,606] Trial 2 pruned. \n",
                        "[I 2026-01-12 16:15:02,642] Trial 3 pruned. \n",
                        "[I 2026-01-12 16:17:30,691] Trial 4 finished with value: 0.6006313737645839 and parameters: {'lr': 0.0003646439558980723, 'weight_decay': 0.00012172847081122418, 'hidden_dim': 512, 'dropout_rate': 0.40889790771866297, 'epochs': 8, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.6006313737645839.\n",
                        "[I 2026-01-12 16:18:01,187] Trial 5 pruned. \n",
                        "[I 2026-01-12 16:21:25,944] Trial 6 finished with value: 0.6410068448796962 and parameters: {'lr': 0.0011103647313054626, 'weight_decay': 7.162786999897333e-05, 'hidden_dim': 512, 'dropout_rate': 0.22574239243053068, 'epochs': 13, 'activation': 'relu', 'optimizer': 'SGD'}. Best is trial 4 with value: 0.6006313737645839.\n",
                        "[I 2026-01-12 16:21:41,856] Trial 7 pruned. \n",
                        "[I 2026-01-12 16:23:01,421] Trial 8 finished with value: 0.6206161690020712 and parameters: {'lr': 0.00010325337616482048, 'weight_decay': 0.00010507384024181397, 'hidden_dim': 64, 'dropout_rate': 0.47716388156500766, 'epochs': 10, 'activation': 'elu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.6006313737645839.\n",
                        "[I 2026-01-12 16:24:02,244] Trial 9 finished with value: 0.631533700152763 and parameters: {'lr': 0.00037126241790405356, 'weight_decay': 1.1851515660043103e-05, 'hidden_dim': 64, 'dropout_rate': 0.4633063543866615, 'epochs': 8, 'activation': 'tanh', 'optimizer': 'AdamW'}. Best is trial 4 with value: 0.6006313737645839.\n",
                        "[I 2026-01-12 16:25:25,629] Trial 10 finished with value: 0.617577388882637 and parameters: {'lr': 0.0029484600244315947, 'weight_decay': 5.3389437745561126e-05, 'hidden_dim': 512, 'dropout_rate': 0.2646934278153025, 'epochs': 5, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.6006313737645839.\n",
                        "[I 2026-01-12 16:26:46,589] Trial 11 finished with value: 0.6057441779090174 and parameters: {'lr': 0.0029072466901725203, 'weight_decay': 4.672941588975309e-05, 'hidden_dim': 512, 'dropout_rate': 0.26238243789332927, 'epochs': 5, 'activation': 'leaky_relu', 'optimizer': 'Adam'}. Best is trial 4 with value: 0.6006313737645839.\n",
                        "[W 2026-01-12 16:28:06,242] Trial 12 failed with parameters: {'lr': 0.002904191288010528, 'weight_decay': 3.258993030030196e-05, 'hidden_dim': 512, 'dropout_rate': 0.3030967181288715, 'epochs': 5, 'activation': 'leaky_relu', 'optimizer': 'Adam'} because of the following error: KeyboardInterrupt().\n",
                        "Traceback (most recent call last):\n",
                        "  File \"/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 205, in _run_trial\n",
                        "    value_or_values = func(trial)\n",
                        "  File \"/var/folders/51/k_yn4qxs0_nfrm1hk39_0m2r0000gn/T/ipykernel_72272/2518146932.py\", line 40, in objective\n",
                        "    loss.backward()\n",
                        "  File \"/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/torch/_tensor.py\", line 625, in backward\n",
                        "    torch.autograd.backward(\n",
                        "  File \"/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/torch/autograd/__init__.py\", line 354, in backward\n",
                        "    _engine_run_backward(\n",
                        "  File \"/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/torch/autograd/graph.py\", line 841, in _engine_run_backward\n",
                        "    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
                        "KeyboardInterrupt\n",
                        "[W 2026-01-12 16:28:06,246] Trial 12 failed with value None.\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[48], line 66\u001b[0m\n\u001b[1;32m     63\u001b[0m pruner \u001b[38;5;241m=\u001b[39m HyperbandPruner(min_resource\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, max_resource\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, reduction_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     65\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m, sampler\u001b[38;5;241m=\u001b[39msampler, pruner\u001b[38;5;241m=\u001b[39mpruner)\n\u001b[0;32m---> 66\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… íŠœë‹ ì™„ë£Œ! Best Params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy\u001b[38;5;241m.\u001b[39mbest_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# [Global Variable Export] ì¤‘ìš”: ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì „ì—­ ë³€ìˆ˜ë¡œ í™•ì •\u001b[39;00m\n",
                        "File \u001b[0;32m/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/optuna/study/study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/optuna/study/_optimize.py:67\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 67\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
                        "File \u001b[0;32m/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/optuna/study/_optimize.py:164\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
                        "File \u001b[0;32m/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/optuna/study/_optimize.py:262\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    258\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    261\u001b[0m ):\n\u001b[0;32m--> 262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
                        "File \u001b[0;32m/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/optuna/study/_optimize.py:205\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
                        "Cell \u001b[0;32mIn[48], line 40\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     38\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     39\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[0;32m---> 40\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Validation for Pruning\u001b[39;00m\n",
                        "File \u001b[0;32m/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/torch/_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[0;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/torch/autograd/graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "import optuna\n",
                "from optuna.samplers import TPESampler\n",
                "from optuna.pruners import HyperbandPruner\n",
                "\n",
                "def objective(trial):\n",
                "    # 1. Hyperparameter Suggestion\n",
                "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
                "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True)\n",
                "    hidden_dim = trial.suggest_categorical('hidden_dim', [64, 128, 256, 512])\n",
                "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
                "    epochs = trial.suggest_int('epochs', 5, 20)\n",
                "    activation = trial.suggest_categorical('activation', ['relu', 'leaky_relu', 'tanh', 'elu'])\n",
                "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'AdamW', 'SGD', 'RMSprop'])\n",
                "\n",
                "    # 2. Model Initialization (Dynamic)\n",
                "    try:\n",
                "        model = MLP_enhance(X.shape[1], hidden_dim=hidden_dim, dropout_rate=dropout_rate, activation=activation)\n",
                "    except TypeError:\n",
                "        model = MLP_enhance(X.shape[1], hidden_dim=hidden_dim)\n",
                "\n",
                "    # 3. Loss & Optimizer\n",
                "    criterion = nn.BCEWithLogitsLoss()\n",
                "\n",
                "    if optimizer_name == 'Adam':\n",
                "        optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
                "    elif optimizer_name == 'AdamW':\n",
                "        optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
                "    elif optimizer_name == 'SGD':\n",
                "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
                "    elif optimizer_name == 'RMSprop':\n",
                "        optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
                "\n",
                "    # 4. Training Loop (with Pruning)\n",
                "    for epoch in range(epochs):\n",
                "        model.train()\n",
                "        for inputs, targets in train_loader:\n",
                "            optimizer.zero_grad()\n",
                "            outputs = model(inputs).squeeze()\n",
                "            loss = criterion(outputs, targets)\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "\n",
                "        # Validation for Pruning\n",
                "        model.eval()\n",
                "        val_loss = 0\n",
                "        with torch.no_grad():\n",
                "            for inputs, targets in val_loader:\n",
                "                outputs = model(inputs).squeeze()\n",
                "                loss = criterion(outputs, targets)\n",
                "                val_loss += loss.item()\n",
                "        avg_val_loss = val_loss / len(val_loader)\n",
                "\n",
                "        # Pruning Check\n",
                "        trial.report(avg_val_loss, epoch)\n",
                "        if trial.should_prune():\n",
                "            raise optuna.TrialPruned()\n",
                "\n",
                "    return avg_val_loss\n",
                "\n",
                "# [Smart Tuning Execution]\n",
                "print(\"ğŸš€ [Smart Tuning] ì´ˆê³ ì†/ì´ˆì •ë°€ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ ì‹œì‘... (TPE + Hyperband)\")\n",
                "sampler = TPESampler(seed=42)\n",
                "pruner = HyperbandPruner(min_resource=1, max_resource=20, reduction_factor=3)\n",
                "\n",
                "study = optuna.create_study(direction='minimize', sampler=sampler, pruner=pruner)\n",
                "study.optimize(objective, n_trials=20)\n",
                "\n",
                "print(f\"âœ… íŠœë‹ ì™„ë£Œ! Best Params: {study.best_params}\")\n",
                "\n",
                "# [Global Variable Export] ì¤‘ìš”: ìµœì  íŒŒë¼ë¯¸í„°ë¥¼ ì „ì—­ ë³€ìˆ˜ë¡œ í™•ì •\n",
                "best_params = study.best_params\n",
                "lr = best_params['lr']\n",
                "weight_decay = best_params['weight_decay']\n",
                "hidden_dim = best_params['hidden_dim']\n",
                "dropout_rate = best_params['dropout_rate']\n",
                "epochs = best_params['epochs']\n",
                "activation = best_params['activation']\n",
                "optimizer_name = best_params['optimizer']\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        ">>> [Final Training] Best Params Applied:\n",
                        "    - Model: MLP_enhance\n",
                        "    - Optimizer: AdamW (lr=0.00555, weight_decay=0.00017)\n",
                        "    - Activation: relu\n",
                        "    - Hidden Dim: 256\n",
                        "    - Dropout: 0.2511\n",
                        "    - Epochs: 12\n",
                        "\n",
                        ">>> Starting Training Loop...\n",
                        "Epoch 01/12: Loss 0.6265\n",
                        "Epoch 02/12: Loss 0.6199\n",
                        "Epoch 03/12: Loss 0.6164\n",
                        "Epoch 04/12: Loss 0.6143\n",
                        "Epoch 05/12: Loss 0.6129\n",
                        "Epoch 06/12: Loss 0.6121\n",
                        "Epoch 07/12: Loss 0.6111\n",
                        "Epoch 08/12: Loss 0.6107\n",
                        "Epoch 09/12: Loss 0.6101\n",
                        "Epoch 10/12: Loss 0.6094\n",
                        "Epoch 11/12: Loss 0.6092\n",
                        "Epoch 12/12: Loss 0.6090\n"
                    ]
                }
            ],
            "source": [
                "# 1. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš© ë° í•™ìŠµ ì¤€ë¹„\n",
                "# (Optuna íŠœë‹ ì…€ì—ì„œ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •ëœ ê°’ë“¤ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤)\n",
                "print(f\"\\n>>> [Final Training] Best Params Applied:\")\n",
                "print(f\"    - Model: MLP_enhance\")\n",
                "print(f\"    - Optimizer: {optimizer_name} (lr={lr:.5f}, weight_decay={weight_decay:.5f})\")\n",
                "print(f\"    - Activation: {activation}\")\n",
                "print(f\"    - Hidden Dim: {hidden_dim}\")\n",
                "print(f\"    - Dropout: {dropout_rate:.4f}\")\n",
                "print(f\"    - Epochs: {epochs}\")\n",
                "\n",
                "# [Model] ëª¨ë¸ ì¬ìƒì„± (Clean Instantiation)\n",
                "model = MLP_enhance(X.shape[1], hidden_dim=hidden_dim, dropout_rate=dropout_rate, activation=activation)\n",
                "\n",
                "# [Loss Function] ì†ì‹¤ í•¨ìˆ˜ ì •ì˜\n",
                "criterion = nn.BCEWithLogitsLoss()\n",
                "\n",
                "# [Optimizer] ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
                "if optimizer_name == 'Adam':\n",
                "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
                "elif optimizer_name == 'AdamW':\n",
                "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
                "elif optimizer_name == 'SGD':\n",
                "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
                "elif optimizer_name == 'RMSprop':\n",
                "    optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
                "\n",
                "# [Training Loop] ìµœì¢… í•™ìŠµ ì§„í–‰\n",
                "print(\"\\n>>> Starting Training Loop...\")\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    for inputs, targets in train_loader:\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(inputs).squeeze()\n",
                "        loss = criterion(outputs, targets)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "    \n",
                "    print(f'Epoch {epoch+1:02d}/{epochs}: Loss {epoch_loss/len(train_loader):.4f}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. ìµœì¢… ëª¨ë¸ í•™ìŠµ (Final Training with Best Params)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        ">>> [Final Training] Best Params Applied:\n",
                        "    - Model: MLP_enhance\n",
                        "    - Optimizer: AdamW (lr=0.00555, weight_decay=0.00017)\n",
                        "    - Activation: relu\n",
                        "    - Hidden Dim: 256\n",
                        "    - Dropout: 0.2511\n",
                        "    - Epochs: 12\n",
                        "\n",
                        ">>> Starting Training Loop...\n",
                        "Epoch 01/12: Loss 0.6266\n",
                        "Epoch 02/12: Loss 0.6202\n",
                        "Epoch 03/12: Loss 0.6165\n",
                        "Epoch 04/12: Loss 0.6143\n",
                        "Epoch 05/12: Loss 0.6130\n",
                        "Epoch 06/12: Loss 0.6118\n",
                        "Epoch 07/12: Loss 0.6111\n",
                        "Epoch 08/12: Loss 0.6106\n",
                        "Epoch 09/12: Loss 0.6101\n",
                        "Epoch 10/12: Loss 0.6095\n",
                        "Epoch 11/12: Loss 0.6094\n",
                        "Epoch 12/12: Loss 0.6090\n"
                    ]
                }
            ],
            "source": [
                "# 1. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì ìš© ë° í•™ìŠµ ì¤€ë¹„\n",
                "# (Optuna íŠœë‹ ì…€ì—ì„œ ì „ì—­ ë³€ìˆ˜ë¡œ ì„¤ì •ëœ ê°’ë“¤ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤)\n",
                "print(f\"\\n>>> [Final Training] Best Params Applied:\")\n",
                "print(f\"    - Model: MLP_enhance\")\n",
                "print(f\"    - Optimizer: {optimizer_name} (lr={lr:.5f}, weight_decay={weight_decay:.5f})\")\n",
                "print(f\"    - Activation: {activation}\")\n",
                "print(f\"    - Hidden Dim: {hidden_dim}\")\n",
                "print(f\"    - Dropout: {dropout_rate:.4f}\")\n",
                "print(f\"    - Epochs: {epochs}\")\n",
                "\n",
                "# [Model] ëª¨ë¸ ì¬ìƒì„± (Clean Instantiation)\n",
                "model = MLP_enhance(X.shape[1], hidden_dim=hidden_dim, dropout_rate=dropout_rate, activation=activation)\n",
                "\n",
                "# [Loss Function] ì†ì‹¤ í•¨ìˆ˜ ì •ì˜\n",
                "criterion = nn.BCEWithLogitsLoss()\n",
                "\n",
                "# [Optimizer] ì˜µí‹°ë§ˆì´ì € ì„¤ì •\n",
                "if optimizer_name == 'Adam':\n",
                "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
                "elif optimizer_name == 'AdamW':\n",
                "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
                "elif optimizer_name == 'SGD':\n",
                "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
                "elif optimizer_name == 'RMSprop':\n",
                "    optimizer = optim.RMSprop(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
                "\n",
                "# [Training Loop] ìµœì¢… í•™ìŠµ ì§„í–‰\n",
                "print(\"\\n>>> Starting Training Loop...\")\n",
                "for epoch in range(epochs):\n",
                "    model.train()\n",
                "    epoch_loss = 0\n",
                "    for inputs, targets in train_loader:\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(inputs).squeeze()\n",
                "        loss = criterion(outputs, targets)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "    \n",
                "    print(f'Epoch {epoch+1:02d}/{epochs}: Loss {epoch_loss/len(train_loader):.4f}')\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ‘¨â€ğŸ’» Developer's Log: ë§Œì¡±, ê·¸ë¦¬ê³  ìš•ì‹¬\n",
                "- **ì„±ê³¼**: ì—­ì‹œ BNê³¼ Dropoutì€ ë°°ì‹ í•˜ì§€ ì•ŠëŠ”ë‹¤. ëª¨ë¸ì´ í›¨ì”¬ ì•ˆì •ì ì´ë‹¤. í˜„ì—…ì—ì„œ DL2 ì •ë„ë©´ \"ë°°í¬ ê°€ëŠ¥í•œ ìˆ˜ì¤€\"ì´ë‹¤.\n",
                "- **ìš•ì‹¬**: í•˜ì§€ë§Œ ì—”ì§€ë‹ˆì–´ë¡œì„œ ê¶ê¸ˆí•˜ë‹¤. ì´ë¯¸ì§€ ì²˜ë¦¬ ë¶„ì•¼ì—ì„œ ì“´ë‹¤ëŠ” **SOTA(State-of-the-Art) ê¸°ìˆ **ë“¤ì„ ì“°ë©´ ì–¼ë§ˆë‚˜ ë” ì¢‹ì•„ì§ˆê¹Œ?\n",
                "- **Next Step**: \"ëì„ ë³´ì.\" ResNetì˜ Residual Connection, ê·¸ë¦¬ê³  ì–´ë ¤ìš´ ë¬¸ì œì— ì§‘ì¤‘í•˜ëŠ” Focal Lossê¹Œì§€ ë‹¤ ë„£ì–´ë³´ì.\n",
                "\n",
                "ğŸ‘‰ **[Next: DL3.ipynb - The Over-Engineering]**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5. ëª¨ë¸ í‰ê°€ ë° ê²°ê³¼ ì €ì¥ (Evaluation & Artifacts)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        ">>> Generating Verification Dashboard (Korean)...\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "text/markdown": [
                            "### ğŸ“Š ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>KPI</th>\n",
                            "      <th>Value</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>PR-AUC (Average Precision)</td>\n",
                            "      <td>0.898414</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>ìƒìœ„ 5% ì •ë°€ë„ (Precision)</td>\n",
                            "      <td>0.941610</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>ìƒìœ„ 5% ì¬í˜„ìœ¨ (Recall)</td>\n",
                            "      <td>0.057528</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>ìƒìœ„ 5% ë¦¬í”„íŠ¸ (Lift)</td>\n",
                            "      <td>1.150613</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                          KPI     Value\n",
                            "0  PR-AUC (Average Precision)  0.898414\n",
                            "1       ìƒìœ„ 5% ì •ë°€ë„ (Precision)  0.941610\n",
                            "2          ìƒìœ„ 5% ì¬í˜„ìœ¨ (Recall)  0.057528\n",
                            "3            ìƒìœ„ 5% ë¦¬í”„íŠ¸ (Lift)  1.150613"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/markdown": [
                            "### ğŸ“ˆ ìƒì„¸ ë­í‚¹ ì§€í‘œ (Top K%)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.Markdown object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Top_K</th>\n",
                            "      <th>Precision</th>\n",
                            "      <th>Recall</th>\n",
                            "      <th>Lift</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>5%</td>\n",
                            "      <td>0.941610</td>\n",
                            "      <td>0.057528</td>\n",
                            "      <td>1.150613</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>10%</td>\n",
                            "      <td>0.934050</td>\n",
                            "      <td>0.114132</td>\n",
                            "      <td>1.141375</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>15%</td>\n",
                            "      <td>0.929648</td>\n",
                            "      <td>0.170398</td>\n",
                            "      <td>1.135996</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>20%</td>\n",
                            "      <td>0.925233</td>\n",
                            "      <td>0.226116</td>\n",
                            "      <td>1.130600</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>25%</td>\n",
                            "      <td>0.920643</td>\n",
                            "      <td>0.281248</td>\n",
                            "      <td>1.124992</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>30%</td>\n",
                            "      <td>0.915574</td>\n",
                            "      <td>0.335636</td>\n",
                            "      <td>1.118797</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "  Top_K  Precision    Recall      Lift\n",
                            "0    5%   0.941610  0.057528  1.150613\n",
                            "1   10%   0.934050  0.114132  1.141375\n",
                            "2   15%   0.929648  0.170398  1.135996\n",
                            "3   20%   0.925233  0.226116  1.130600\n",
                            "4   25%   0.920643  0.281248  1.124992\n",
                            "5   30%   0.915574  0.335636  1.118797"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/var/folders/51/k_yn4qxs0_nfrm1hk39_0m2r0000gn/T/ipykernel_72272/2520853021.py:59: UserWarning: Glyph 51116 (\\N{HANGUL SYLLABLE JAE}) missing from font(s) DejaVu Sans.\n",
                        "  plt.tight_layout()\n",
                        "/var/folders/51/k_yn4qxs0_nfrm1hk39_0m2r0000gn/T/ipykernel_72272/2520853021.py:59: UserWarning: Glyph 54788 (\\N{HANGUL SYLLABLE HYEON}) missing from font(s) DejaVu Sans.\n",
                        "  plt.tight_layout()\n",
                        "/var/folders/51/k_yn4qxs0_nfrm1hk39_0m2r0000gn/T/ipykernel_72272/2520853021.py:59: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
                        "  plt.tight_layout()\n",
                        "/var/folders/51/k_yn4qxs0_nfrm1hk39_0m2r0000gn/T/ipykernel_72272/2520853021.py:59: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
                        "  plt.tight_layout()\n",
                        "/var/folders/51/k_yn4qxs0_nfrm1hk39_0m2r0000gn/T/ipykernel_72272/2520853021.py:59: UserWarning: Glyph 48128 (\\N{HANGUL SYLLABLE MIL}) missing from font(s) DejaVu Sans.\n",
                        "  plt.tight_layout()\n",
                        "/var/folders/51/k_yn4qxs0_nfrm1hk39_0m2r0000gn/T/ipykernel_72272/2520853021.py:59: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
                        "  plt.tight_layout()\n",
                        "/var/folders/51/k_yn4qxs0_nfrm1hk39_0m2r0000gn/T/ipykernel_72272/2520853021.py:59: UserWarning: Glyph 44257 (\\N{HANGUL SYLLABLE GOG}) missing from font(s) DejaVu Sans.\n",
                        "  plt.tight_layout()\n",
                        "/var/folders/51/k_yn4qxs0_nfrm1hk39_0m2r0000gn/T/ipykernel_72272/2520853021.py:59: UserWarning: Glyph 49440 (\\N{HANGUL SYLLABLE SEON}) missing from font(s) DejaVu Sans.\n",
                        "  plt.tight_layout()\n",
                        "/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
                        "  fig.canvas.print_figure(bytes_io, **kw)\n",
                        "/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 48128 (\\N{HANGUL SYLLABLE MIL}) missing from font(s) DejaVu Sans.\n",
                        "  fig.canvas.print_figure(bytes_io, **kw)\n",
                        "/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
                        "  fig.canvas.print_figure(bytes_io, **kw)\n",
                        "/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 44257 (\\N{HANGUL SYLLABLE GOG}) missing from font(s) DejaVu Sans.\n",
                        "  fig.canvas.print_figure(bytes_io, **kw)\n",
                        "/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 49440 (\\N{HANGUL SYLLABLE SEON}) missing from font(s) DejaVu Sans.\n",
                        "  fig.canvas.print_figure(bytes_io, **kw)\n",
                        "/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 51116 (\\N{HANGUL SYLLABLE JAE}) missing from font(s) DejaVu Sans.\n",
                        "  fig.canvas.print_figure(bytes_io, **kw)\n",
                        "/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 54788 (\\N{HANGUL SYLLABLE HYEON}) missing from font(s) DejaVu Sans.\n",
                        "  fig.canvas.print_figure(bytes_io, **kw)\n",
                        "/opt/anaconda3/envs/churn_env/lib/python3.10/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
                        "  fig.canvas.print_figure(bytes_io, **kw)\n"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 600x500 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# --- [Evaluation & Metrics Restoration] ---\n",
                "import torch\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearn.metrics import precision_recall_curve\n",
                "from app.utils.metrics import evaluate_churn_metrics\n",
                "from IPython.display import display, Markdown\n",
                "\n",
                "# 1. í‰ê°€ ëª¨ë“œ ì „í™˜ (Evaluation Mode)\n",
                "model.eval()  # 'ì‹œí—˜ ëª¨ë“œ'ë¡œ ì „í™˜ (Dropout êº¼ì§)\n",
                "all_targets = []\n",
                "all_probs = []\n",
                "\n",
                "# 2. ì˜ˆì¸¡ ìˆ˜í–‰ (Inference)\n",
                "with torch.no_grad(): # í‰ê°€ ë•ŒëŠ” ë¯¸ë¶„(ê³„ì‚°ê°’ ì €ì¥) ë¶ˆí•„ìš”\n",
                "    for inputs, targets in test_loader:\n",
                "        outputs = model(inputs).squeeze()\n",
                "        probs = torch.sigmoid(outputs)       # í™•ë¥ ê°’(0~1)ìœ¼ë¡œ ë³€í™˜\n",
                "        all_targets.extend(targets.numpy())  # ì •ë‹µ ëª¨ìœ¼ê¸°\n",
                "        all_probs.extend(probs.numpy())      # ì˜ˆì¸¡ê°’ ëª¨ìœ¼ê¸°\n",
                "\n",
                "y_test_np = np.array(all_targets)\n",
                "y_prob_np = np.array(all_probs)\n",
                "\n",
                "# 3. ì„±ì í‘œ ì‘ì„± (Metrics Calculation)\n",
                "# ìš°ë¦¬ê°€ ë§Œë“  ì»¤ìŠ¤í…€ í•¨ìˆ˜ë¡œ ë‹¤ì–‘í•œ ì§€í‘œ ê³„ì‚° (í•œêµ­ì–´ í¬ë§·)\n",
                "metrics = evaluate_churn_metrics(y_test_np, y_prob_np)\n",
                "\n",
                "# 4. ìš”ì•½í‘œì™€ ë­í‚¹í‘œ ë¶„ë¦¬\n",
                "summary_metrics = {k: v for k, v in metrics.items() if k != 'ranking'}\n",
                "ranking_metrics = metrics.get('ranking', [])\n",
                "\n",
                "summary_df = pd.DataFrame(list(summary_metrics.items()), columns=['KPI', 'Value'])\n",
                "ranking_df = pd.DataFrame(ranking_metrics)\n",
                "\n",
                "# 5. ëŒ€ì‹œë³´ë“œ ì¶œë ¥ (Dashboard)\n",
                "print(f'>>> Generating Verification Dashboard (Korean)...\\n')\n",
                "display(Markdown('### ğŸ“Š ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ'))\n",
                "display(summary_df)\n",
                "\n",
                "display(Markdown('### ğŸ“ˆ ìƒì„¸ ë­í‚¹ ì§€í‘œ (Top K%)'))\n",
                "display(ranking_df)\n",
                "\n",
                "# 6. ê·¸ë˜í”„ ê·¸ë¦¬ê¸° (Plots)\n",
                "figures = {}\n",
                "\n",
                "# (1) PR ê³¡ì„  (Precision-Recall Curve)\n",
                "fig_pr = plt.figure(figsize=(6, 5))\n",
                "precision_curve, recall_curve, _ = precision_recall_curve(y_test_np, y_prob_np)\n",
                "pr_auc_val = metrics.get('PR-AUC (Average Precision)', 0.0)\n",
                "\n",
                "plt.plot(recall_curve, precision_curve, label=f'PR-AUC = {pr_auc_val:.4f}', color='green', lw=2)\n",
                "plt.title('PR ê³¡ì„  (Precision-Recall Curve)')\n",
                "plt.xlabel('ì¬í˜„ìœ¨ (Recall)')\n",
                "plt.ylabel('ì •ë°€ë„ (Precision)')\n",
                "plt.legend(loc='lower left')\n",
                "plt.grid(True, alpha=0.3)\n",
                "plt.tight_layout()\n",
                "figures['pr_curve'] = fig_pr\n",
                "display(fig_pr)\n",
                "plt.close()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        ">>> [Artifacts] Starting saving process for mlp_enhance...\n",
                        "  - [Clean] Deleted existing file: /Users/gimdabin/SKN23-2nd-3Team/models/dl/mlp_enhance.pt\n",
                        "  - Model saved to /Users/gimdabin/SKN23-2nd-3Team/models/dl/mlp_enhance.pt\n",
                        "  - [Clean] Deleted existing file: /Users/gimdabin/SKN23-2nd-3Team/models/metrics/mlp_enhance_metrics.json\n",
                        "  - Metrics saved to /Users/gimdabin/SKN23-2nd-3Team/models/metrics/mlp_enhance_metrics.json\n",
                        "  - Scaler saved to /Users/gimdabin/SKN23-2nd-3Team/models/dl/mlp_enhance_scaler.pkl\n",
                        "  - [Clean] Deleted existing file: /Users/gimdabin/SKN23-2nd-3Team/assets/training/mlp_enhance_pr_curve.png\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/gimdabin/SKN23-2nd-3Team/app/utils/artifacts.py:103: UserWarning: Glyph 51221 (\\N{HANGUL SYLLABLE JEONG}) missing from font(s) DejaVu Sans.\n",
                        "  fig.savefig(fig_path, bbox_inches=\"tight\")\n",
                        "/Users/gimdabin/SKN23-2nd-3Team/app/utils/artifacts.py:103: UserWarning: Glyph 48128 (\\N{HANGUL SYLLABLE MIL}) missing from font(s) DejaVu Sans.\n",
                        "  fig.savefig(fig_path, bbox_inches=\"tight\")\n",
                        "/Users/gimdabin/SKN23-2nd-3Team/app/utils/artifacts.py:103: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
                        "  fig.savefig(fig_path, bbox_inches=\"tight\")\n",
                        "/Users/gimdabin/SKN23-2nd-3Team/app/utils/artifacts.py:103: UserWarning: Glyph 44257 (\\N{HANGUL SYLLABLE GOG}) missing from font(s) DejaVu Sans.\n",
                        "  fig.savefig(fig_path, bbox_inches=\"tight\")\n",
                        "/Users/gimdabin/SKN23-2nd-3Team/app/utils/artifacts.py:103: UserWarning: Glyph 49440 (\\N{HANGUL SYLLABLE SEON}) missing from font(s) DejaVu Sans.\n",
                        "  fig.savefig(fig_path, bbox_inches=\"tight\")\n",
                        "/Users/gimdabin/SKN23-2nd-3Team/app/utils/artifacts.py:103: UserWarning: Glyph 51116 (\\N{HANGUL SYLLABLE JAE}) missing from font(s) DejaVu Sans.\n",
                        "  fig.savefig(fig_path, bbox_inches=\"tight\")\n",
                        "/Users/gimdabin/SKN23-2nd-3Team/app/utils/artifacts.py:103: UserWarning: Glyph 54788 (\\N{HANGUL SYLLABLE HYEON}) missing from font(s) DejaVu Sans.\n",
                        "  fig.savefig(fig_path, bbox_inches=\"tight\")\n",
                        "/Users/gimdabin/SKN23-2nd-3Team/app/utils/artifacts.py:103: UserWarning: Glyph 50984 (\\N{HANGUL SYLLABLE YUL}) missing from font(s) DejaVu Sans.\n",
                        "  fig.savefig(fig_path, bbox_inches=\"tight\")\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "  - Figure 'pr_curve' saved to /Users/gimdabin/SKN23-2nd-3Team/assets/training/mlp_enhance_pr_curve.png\n",
                        "  - [Clean] Deleted existing file: /Users/gimdabin/SKN23-2nd-3Team/reports/training/mlp_enhance_report.md\n",
                        "  - Report saved to /Users/gimdabin/SKN23-2nd-3Team/reports/training/mlp_enhance_report.md\n",
                        ">>> [Artifacts] All artifacts saved successfully.\n"
                    ]
                }
            ],
            "source": [
                "from app.utils.artifacts import save_model_and_artifacts\n",
                "\n",
                "# 1. ë¦¬í¬íŠ¸ ë‚´ìš© ì‘ì„± (Markdown)\n",
                "# Evaluation Cellì—ì„œ ìƒì„±ëœ summary_df, ranking_dfë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
                "report_content = f\"# ìµœì¢… ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ - mlp_enhance\\n\\n## ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ\\n{summary_df.to_markdown(index=False)}\\n\\n## ìƒì„¸ ë­í‚¹ ì§€í‘œ (Top K%)\\n{ranking_df.to_markdown(index=False)}\"\n",
                "\n",
                "# 2. ëª¨ë¸ ë° ê²°ê³¼ë¬¼ ì €ì¥ (Utils í•¨ìˆ˜ ì‚¬ìš©)\n",
                "# save_model_and_artifacts í•¨ìˆ˜ê°€ ë‚´ë¶€ì ìœ¼ë¡œ ê¸°ì¡´ íŒŒì¼ì„ ë®ì–´ì“°ê¸°(Overwrite) í•©ë‹ˆë‹¤.\n",
                "save_model_and_artifacts(\n",
                "    model=model,\n",
                "    model_name=\"mlp_enhance\",\n",
                "    model_type=\"dl\",\n",
                "    metrics=metrics,\n",
                "    scaler=scaler,\n",
                "    figures=figures,\n",
                "    config=best_params,  # Optuna ìµœì  íŒŒë¼ë¯¸í„°\n",
                "    report=report_content\n",
                ")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 6. ì¸ì‚¬ì´íŠ¸ ë¦¬í¬íŠ¸ ìë™ ìƒì„± (Insight Generation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… [Insight] ë¦¬í¬íŠ¸ê°€ ../../reports/insights/dl/mlp_enhance_insight.md ê²½ë¡œì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
                    ]
                }
            ],
            "source": [
                "# --- [Insight Generation] ì¸ì‚¬ì´íŠ¸ ë„ì¶œ ---\n",
                "import os\n",
                "\n",
                "# 1. í´ë” í™•ì¸\n",
                "insight_dir = '../../reports/insights/dl/'\n",
                "if not os.path.exists(insight_dir):\n",
                "    os.makedirs(insight_dir)\n",
                "\n",
                "# 2. ë¦¬í¬íŠ¸ ë‚´ìš© ì‘ì„± (Winner's Report included)\n",
                "# ì£¼ìš” ì§€í‘œë¥¼ ë½‘ì•„ì„œ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¦\n",
                "try:\n",
                "    pr_auc_val = float(metrics.get(\"PR-AUC (Average Precision)\", 0.0))\n",
                "    top_5_prec = float(metrics.get(\"ìƒìœ„ 5% ì •ë°€ë„ (Precision)\", 0.0)) * 100\n",
                "except Exception as e:\n",
                "    print(f'Warning: Metric extraction failed ({e}). Using placeholders.')\n",
                "    pr_auc_val = 0.0\n",
                "    top_5_prec = 0.0\n",
                "\n",
                "insight_content = f\"\"\"# ğŸ† MLP Enhance - Winner's Report\\n\\n\n",
                "## 1. í•µì‹¬ ì„±ê³¼\\n\n",
                "- **ëª¨ë¸ íŠ¹ì§•**: Batch Normalizationê³¼ Dropout ì ìš©ìœ¼ë¡œ í•™ìŠµ ì•ˆì •ì„± í™•ë³´.\\n\n",
                "- **ì£¼ìš” ì§€í‘œ**:\\n\n",
                "    - PR-AUC: {pr_auc_val:.4f}\\n\n",
                "    - ìƒìœ„ 5% ì •ë°€ë„: **{top_5_prec:.2f}%**\\n\n",
                "\\n\n",
                "## 2. ë¹„ì¦ˆë‹ˆìŠ¤ ê²°ë¡ \\n\n",
                "> \"DL3(Advanced)ë³´ë‹¤ êµ¬ì¡°ëŠ” ë‹¨ìˆœí•˜ì§€ë§Œ ì„±ëŠ¥ì€ ë” ìš°ìˆ˜í•˜ë¯€ë¡œ **'ìµœì¢… ë°°í¬ ëª¨ë¸'**ë¡œ ì„ ì •í•œë‹¤.\"\\n\n",
                "\\n\n",
                "ì´ ëª¨ë¸ì€ ê³¼ì í•© ìœ„í—˜ì´ ë‚®ê³  ì¶”ë¡  ì†ë„ê°€ ë¹¨ë¼, ì‹¤ì‹œê°„ ì´íƒˆ ë°©ì§€ ë§ˆì¼€íŒ…ì— ì¦‰ì‹œ íˆ¬ì… ê°€ëŠ¥í•˜ë‹¤.\\n\n",
                "\"\"\"\n",
                "\n",
                "# 3. íŒŒì¼ ì €ì¥\n",
                "file_path = os.path.join(insight_dir, 'mlp_enhance_insight.md')\n",
                "with open(file_path, 'w', encoding='utf-8') as f:\n",
                "    f.write(insight_content)\n",
                "\n",
                "# 4. ì™„ë£Œ ë©”ì‹œì§€\n",
                "print(f'âœ… [Insight] ë¦¬í¬íŠ¸ê°€ {file_path} ê²½ë¡œì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 7. ìƒì„¸ í‰ê°€ ë°ì´í„° ì €ì¥ (For Dashboard Visualization)\n",
                "> ì´ ì•„ë˜ì˜ ì½”ë“œëŠ” ì‹œê°í™” ëŒ€ì‹œë³´ë“œë¥¼ ìœ„í•œ **ì¶”ê°€ì ì¸ JSON ë°ì´í„°**ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "# 1. ê³µí†µ ê²½ë¡œ ë° ID ì„¤ì •\n",
                "MODEL_ID = \"dl__mlp_enhance\"\n",
                "MODEL_NAME = \"mlp_enhance\"\n",
                "\n",
                "EVAL_DIR = Path(\"../../models/eval/dlmlp_enhance\")\n",
                "METRIC_DIR = Path(\"../../models/metrics\")\n",
                "\n",
                "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
                "METRIC_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# 2. Model Card (ëª¨ë¸ ì‹ ì› ì •ë³´) ì €ì¥\n",
                "model_card = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"display_name\": \"MLP_enhance (DL)\",\n",
                "    \"category\": \"DL\",\n",
                "    \"split\": \"test\"\n",
                "}\n",
                "\n",
                "with open(EVAL_DIR / \"model_card.json\", \"w\") as f:\n",
                "    json.dump(model_card, f, indent=2, ensure_ascii=False)\n",
                "\n",
                "# 3. PR AUC ë©”íŠ¸ë¦­ ì €ì¥\n",
                "pr_metrics = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"split\": \"test\",\n",
                "    \"pr_auc\": float(metrics.get(\"PR-AUC (Average Precision)\", 0.0))\n",
                "}\n",
                "\n",
                "with open(EVAL_DIR / \"pr_metrics.json\", \"w\") as f:\n",
                "    json.dump(pr_metrics, f, indent=2, ensure_ascii=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Top-K ë©”íŠ¸ë¦­ (ìƒìœ„ N% ì„±ëŠ¥) ì €ì¥\n",
                "base_rate = float(y_test_np.mean()) # ì „ì²´ ì´íƒˆë¥ \n",
                "\n",
                "topk_metrics = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"split\": \"test\",\n",
                "    \"base_rate\": base_rate,\n",
                "    \"metrics_by_k\": []\n",
                "}\n",
                "\n",
                "# DataFrameì˜ í–‰ì„ ëŒë©´ì„œ ì €ì¥\n",
                "for row in ranking_df.to_dict(orient=\"records\"):\n",
                "    k_pct = int(str(row[\"Top_K\"]).replace(\"%\", \"\").strip())\n",
                "\n",
                "    topk_metrics[\"metrics_by_k\"].append({\n",
                "        \"k_pct\": k_pct,\n",
                "        \"precision_at_k\": float(row[\"Precision\"]),\n",
                "        \"recall_at_k\": float(row[\"Recall\"]),\n",
                "        \"lift_at_k\": float(row[\"Lift\"]),\n",
                "    })\n",
                "\n",
                "with open(EVAL_DIR / \"topk_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
                "    json.dump(topk_metrics, f, indent=2, ensure_ascii=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Top-K Cutoffs (ì ìˆ˜ ì»¤íŠ¸ë¼ì¸) ì €ì¥\n",
                "sorted_scores = np.sort(y_prob_np)[::-1] # ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬\n",
                "n_total = len(sorted_scores)\n",
                "\n",
                "cutoffs = []\n",
                "\n",
                "for k in [5, 10, 15, 30]:\n",
                "    n_selected = int(np.floor(n_total * k / 100)) # ìƒìœ„ k% ì¸ì› ìˆ˜\n",
                "    t_k = float(sorted_scores[n_selected - 1])    # ê·¸ ì¸ì› ìˆ˜ì¼ ë•Œì˜ ìµœì € ì ìˆ˜ (ì»¤íŠ¸ë¼ì¸)\n",
                "\n",
                "    cutoffs.append({\n",
                "        \"k_pct\": k,\n",
                "        \"n_selected\": n_selected,\n",
                "        \"t_k\": t_k\n",
                "    })\n",
                "\n",
                "topk_cutoffs = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"split\": \"test\",\n",
                "    \"n_total\": n_total,\n",
                "    \"n_selected_rule\": \"floor\",\n",
                "    \"tie_policy\": \"sort_and_take_top_n\",\n",
                "    \"cutoffs_by_k\": cutoffs\n",
                "}\n",
                "\n",
                "with open(EVAL_DIR / \"topk_cutoffs.json\", \"w\") as f:\n",
                "    json.dump(topk_cutoffs, f, indent=2, ensure_ascii=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… score_percentiles ì €ì¥ ì™„ë£Œ: ../../models/metrics/mlp_enhance_score_percentiles.json\n"
                    ]
                }
            ],
            "source": [
                "# 6. ì ìˆ˜ ë¶„í¬ ë°±ë¶„ìœ„ (Percentiles) ì €ì¥\n",
                "percentiles = [1, 5, 10, 20, 30, 50]\n",
                "# ìƒìœ„ n%ì— í•´ë‹¹í•˜ëŠ” ì ìˆ˜ ê³„ì‚° (ì˜ˆ: ìƒìœ„ 1% ì ìˆ˜ëŠ” min(score) of top 1%)\n",
                "scores = np.percentile(y_prob_np, 100 - np.array(percentiles))\n",
                "\n",
                "score_percentiles = {\n",
                "    \"model_id\": MODEL_ID,\n",
                "    \"split\": \"test\",\n",
                "    \"percentiles\": [\n",
                "        {\"pct\": p, \"score\": float(s)}\n",
                "        for p, s in zip(percentiles, scores)\n",
                "    ]\n",
                "}\n",
                "\n",
                "# íŒŒì¼ëª… ê·œì¹™ (metrics/mlp_enhance_score_percentiles.json)\n",
                "save_path = METRICS_DIR / f\"{MODEL_NAME}_score_percentiles.json\"\n",
                "\n",
                "with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
                "    json.dump(score_percentiles, f, indent=2, ensure_ascii=False)\n",
                "\n",
                "print(f\"âœ… score_percentiles ì €ì¥ ì™„ë£Œ: {save_path}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "churn_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.19"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
