{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51c4dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) torch.Size([2, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      6\u001b[39m y = torch.FloatTensor([[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m],\n\u001b[32m      7\u001b[39m                        [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m]])\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(x.size(),y.size())\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m)\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.FloatTensor([[1, 2],\n",
    "                       [3, 4],\n",
    "                       [5, 6]])\n",
    "y = torch.FloatTensor([[1, 2],\n",
    "                       [1, 2]])\n",
    "\n",
    "print(x.size(),y.size())\n",
    "\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36beef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2]) torch.Size([3, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(\n",
    "    [[[1, 2],\n",
    "     [3, 4],\n",
    "     [5, 6]],\n",
    "\n",
    "    [[7, 8],\n",
    "     [9, 10],\n",
    "     [11, 12]],\n",
    "\n",
    "    [[13, 14],\n",
    "     [15, 16],\n",
    "     [17, 18]]] # (3, 3, 2)\n",
    ")\n",
    "y = torch.FloatTensor(\n",
    "    [[[1, 2, 2],\n",
    "     [1, 2, 2]],\n",
    "\n",
    "    [[1, 3, 3],\n",
    "     [1, 3, 3]],\n",
    "\n",
    "    [[1, 4, 4],\n",
    "     [1, 4, 4]]] # (3, 2, 3)\n",
    ")\n",
    "\n",
    "print(x.size(), y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "768b2aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, y)  # 행렬 곱 수행 (마지막 2차원 기준)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a30aa4a",
   "metadata": {},
   "source": [
    "- 마지막 2개 차원을 기준으로 행렬곱 수행\n",
    "- batch 차원은 같아야 한다. (아니면 11이라도 되서 브로드캐스팅이라도 되어야 한다.)   \n",
    "(3, 3, 2) x (3, 2, 3) = (3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e8cafd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 3차원에서만 사용할 수 있는 행렬곱 연산 bmm(batch matrix multiplication)\n",
    "z = torch.bmm(x, y) # 행렬 곱 수행 (마지막 2차원 기준)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e96cb9",
   "metadata": {},
   "source": [
    "torch.bmm\n",
    "입력이 반드시 3차원 텐서 (B, N, M) @ (B, M, P) = (B, N, P)   \n",
    "각 batch는 batch마다 독립적으로 행렬곱 연산   \n",
    "| 구분 | torch.matmul | torch.bmm |\n",
    "| --- | --- | --- |\n",
    "| 입력 차원 | 1D ~~ ND | 3D만 |\n",
    "| 출력 차원 | 자동 해석 + 브로드캐스팅 | Batch크기 동일해야 한다. |\n",
    "| 연산 범위 | 범용 행렬곱 | 배치 행렬곱 |\n",
    "| 유연성 | 높다 | 낮다 |\n",
    "\n",
    "bmm은 3차원 배치 행렬곱 전용   \n",
    "matmul은 차원 수에 따라 자동으로 처리되는 범용 행렬곱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ee514",
   "metadata": {},
   "source": [
    ".T(전치): 를 이용해서 입력 차원과 곱셈이 가능하도록 맞춘다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c95e1740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "    [[1., 2., 3.]]\n",
    ")\n",
    "W = torch.tensor(\n",
    "    [[0.1, 0.2, 0.3],\n",
    "     [0.4, 0.5, 0.6]]\n",
    ")\n",
    "\n",
    "print(x.size(), W.size()) # (1, 3), (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fa7cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = torch.matmul(x, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d04caf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.T.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3177c88d",
   "metadata": {},
   "source": [
    ".T (전치 Transpose) : (2, 3) -> (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82715764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.matmul(x, W.T) # (1, 3) @ (3, 2) -> (1, 2)\n",
    "\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b6847",
   "metadata": {},
   "source": [
    "행렬곱 절대원칙   \n",
    "행렬곱에서 마지막 두 차원은 반ㄷ드시 아래와 같아야 한다.   \n",
    "(..., N, M) @ (... M, P) -> M == M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4631859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(\n",
    "    [[[1, 2],\n",
    "     [3, 4],\n",
    "     [5, 6]],\n",
    "\n",
    "    [[7, 8],\n",
    "     [9, 10],\n",
    "     [11, 12]],\n",
    "\n",
    "    [[13, 14],\n",
    "     [15, 16],\n",
    "     [17, 18]]] # (3, 3, 2)\n",
    ")\n",
    "W = torch.tensor(\n",
    "    [[0.1, 0.2, 0.3],\n",
    "     [0.4, 0.5, 0.6]]\n",
    ")\n",
    "\n",
    "print(x.size(), W.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68bf9317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, W)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4af40b",
   "metadata": {},
   "source": [
    "브로드캐스팅 (2, 3) --> batch 차원 추가 (11, 2, 3) -> batch 방향으로 복제 -> (3, 2, 3)   \n",
    "(3, 3 ,2) @ (3, 2, 3) => (3, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5480d2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 2]) torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[[1, 2],\n",
    "                        [3, 4],\n",
    "                        [5, 6]],\n",
    "\n",
    "                        [[7, 8],\n",
    "                        [9, 10],\n",
    "                        [11, 12]],\n",
    "\n",
    "                        [[13, 14],\n",
    "                        [15, 16],\n",
    "                        [17, 18]]]) # (3, 3, 2)\n",
    "\n",
    "W = torch.tensor([[[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6]],\n",
    "\n",
    "                  [[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6]],\n",
    "\n",
    "                  [[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6]],\n",
    "\n",
    "                  [[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6]]]) # (4, 2, 3)\n",
    "\n",
    "print(x.size(),W.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc354cf",
   "metadata": {},
   "source": [
    "batch 차원이 3 !== 4 (맞지 않음)   \n",
    "내적 계산은 맞으나 자동으로 batch가 브로드캐스팅 되지않음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2bce10",
   "metadata": {},
   "source": [
    "- 내적 차원 불일치 한 경우 : 불가\n",
    "- batch 차원이 맞지 않는데 브로드캐스팅 조건에도 맞지 않은 경우 : 불가\n",
    "- 내적 차원 일치 + batch 차원이 맞는 경우 : 가능\n",
    "- 내적 차원 일치 + batch 차원이 맞지 않는데, batch차원 브로드캐스팅 가능한 경우 : 가능 (자동 처리)   \n",
    "=> batch는 행렬곱 연산 결과 자체에는 상관없으나, 형태가 맞아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9811b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 2)\n",
    "W = torch.randn(2, 4, 2)\n",
    "\n",
    "# y = torch.bmm(x, W.T) -> 3차원 이상은 transpose()를 이용하여 명시적으로 교환\n",
    "y = torch.bmm(x, W.transpose(1, 2))\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf89cf6",
   "metadata": {},
   "source": [
    "transpose(dim1, dim2) : 지정된 2개의 차원을 교환   \n",
    "(2, 4, 2) -> (2, 2, 4) : 내적 차원 계산할 수 있도록 전치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d21e93c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.tensor(\n",
    "    [[1., 2., 3.]]\n",
    ")\n",
    "\n",
    "W = torch.tensor(\n",
    "    [[0.1, 0.2, 0.3],\n",
    "     [0.4, 0.5, 0.6]]\n",
    ")\n",
    "\n",
    "print(x.size()) # (1, 3)\n",
    "print(W.size()) # (2 ,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7d1b3f",
   "metadata": {},
   "source": [
    "nn.Linear 레이어 생성 (bias 생략) : 수동으로 만든 행렬곱과 정확히 동일한 결과가 나온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "899a535a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(\n",
    "    in_features = 3,  # 입력 벡터의 길이(x의 열), 행렬곱에서는 입력의 열 차원\n",
    "    out_features = 2, # 출력 벡터의 길이(출력의 행)\n",
    "    bias = False      # bias 항 제외 -> 순수 행렬곱만 수행한 결과\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "303c3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W를 nn.Linear 레이어에 직접 복사\n",
    "with torch.no_grad():      # 그래디언트 추적 비활성화 (가중치 수동 조절)\n",
    "    linear.weight.copy_(W) # Linear 레이어의 가중치를 W값으로 직접 덮어쓰기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e350a22",
   "metadata": {},
   "source": [
    "copy_(W) : 대입해주는게 아니라 값만 복사   \n",
    "=> 파라미터 객체는 그대로 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fff3402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4000, 3.2000]], grad_fn=<MmBackward0>) torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "y2 = linear(x)\n",
    "print(y2, y2.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f4502",
   "metadata": {},
   "source": [
    "linear(x) 연산을 했는데 내부적으로 자동으로 x @ W.T 시켜서 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44512498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2. 3.]\n"
     ]
    }
   ],
   "source": [
    "# 항등함수\n",
    "import numpy as np\n",
    "\n",
    "def identity_function(x):\n",
    "    return x\n",
    "\n",
    "x = np.array([1.0, 2.0, 3.0])\n",
    "print(identity_function(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78929567",
   "metadata": {},
   "source": [
    "이진분류 (임계값 기준)   \n",
    "출력값 >= 0.5 : 클래스 1   \n",
    "출력값 < 0.5 : 클래스 0   \n",
    "   \n",
    "   다중분류 (서로 독립된 확률) -> 하나의 데이터가 여러 클래스에 동시에 속할 수 있는 문제를 해결할 수 있다.   \n",
    "      \n",
    "입력값이 한없이 0이나 1에 가까워지면 기울기가 0에 수렴하는 (기울기 소실) 문제가 발생할 수 있다.   \n",
    "=> 주로 은닉층에서는 사용하지 않고 출력층에서만 주로 사용한다.   \n",
    "   \n",
    "   손실함수로는 BCE 사용한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb44ff",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{e^{x_i}}{\\sum_j e^{x_j}}\n",
    "=\n",
    "\\frac{e^{x_i - c}}{\\sum_j e^{x_j - c}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b648dcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
