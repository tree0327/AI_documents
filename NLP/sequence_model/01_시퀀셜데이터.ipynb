{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd92943",
   "metadata": {},
   "source": [
    "# ğŸŒŠ 01. ì‹œí€€ì…œ ë°ì´í„° & RNN (Recurrent Neural Network)\n",
    "\n",
    "## 1. ì‹œí€€ì…œ ë°ì´í„°(Sequential Data)ë€?\n",
    "**\"ìˆœì„œ(Sequence)\"ê°€ ì¤‘ìš”í•œ ë°ì´í„°**ë¥¼ ë§í•©ë‹ˆë‹¤.\n",
    "ìˆœì„œë¥¼ ë°”ê¾¸ë©´ ì˜ë¯¸ê°€ ì™„ì „íˆ ë‹¬ë¼ì§€ê±°ë‚˜ ë§ê°€ì§€ëŠ” ë°ì´í„°ë“¤ì´ì£ .\n",
    "\n",
    "> **ì‰¬ìš´ ë¹„ìœ  (ë„ë¯¸ë…¸)**:  \n",
    "> ë„ë¯¸ë…¸ í•˜ë‚˜ê°€ ì“°ëŸ¬ì§€ë©´, ê·¸ ë‹¤ìŒ ë„ë¯¸ë…¸ë„ ì“°ëŸ¬ì§‘ë‹ˆë‹¤. **ì•ì˜ ì‚¬ê±´ì´ ë’¤ì— ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒ**, ì´ê²ƒì´ ì‹œí€€ì…œ ë°ì´í„°ì˜ í•µì‹¬ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì˜ˆì‹œ\n",
    "- **í…ìŠ¤íŠ¸**: \"ë„ˆë¥¼ ì‚¬ë‘í•´\" vs \"ì‚¬ë‘í•´ ë„ˆë¥¼\" (ìˆœì„œê°€ ë°”ë€Œë©´ ì–´ìƒ‰í•¨)\n",
    "- **ì‹œê³„ì—´(Time Series)**: ì˜¤ëŠ˜ì˜ ì£¼ê°€ëŠ” ì–´ì œ ì£¼ê°€ì˜ ì˜í–¥ì„ ë°›ìŒ.\n",
    "- **ìŒì„±**: \"ì•„\" ì†Œë¦¬ ë‹¤ìŒì— \"ë¹ \"ê°€ ì™€ì•¼ \"ì•„ë¹ \"ê°€ ë¨.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1663e",
   "metadata": {},
   "source": [
    "## 2. RNN: ê¸°ì–µì„ ê°€ì§„ ì‹ ê²½ë§\n",
    "\n",
    "ê¸°ì¡´ì˜ ì‹ ê²½ë§(Feed Forward)ì€ ë°ì´í„°ë¥¼ í•˜ë‚˜ ë³´ê³  ìŠì–´ë²„ë ¸ìŠµë‹ˆë‹¤. (ê¸ˆë¶•ì–´ ê¸°ì–µë ¥ ğŸŸ)\n",
    "í•˜ì§€ë§Œ ë¬¸ì¥ì„ ì´í•´í•˜ë ¤ë©´ **ì• ë‚´ìš©ì„ ê¸°ì–µ**í•˜ê³  ìˆì–´ì•¼ ë’· ë‚´ìš©ì„ ì´í•´í•  ìˆ˜ ìˆì£ .\n",
    "\n",
    "> **ì‰¬ìš´ ë¹„ìœ  (ì´ì–´ë‹¬ë¦¬ê¸°/Relay Race)**: ğŸƒ\n",
    "> - ì²« ë²ˆì§¸ ì„ ìˆ˜ê°€ ë›°ê³  ë‚˜ì„œ, **ë°”í†µ(ê¸°ì–µ, Hidden State)**ì„ ë‘ ë²ˆì§¸ ì„ ìˆ˜ì—ê²Œ ë„˜ê²¨ì¤ë‹ˆë‹¤.\n",
    "> - ë‘ ë²ˆì§¸ ì„ ìˆ˜ëŠ” ë°”í†µì„ ë°›ì•„ ê³„ì† ëœë‹ˆë‹¤.\n",
    "> - ì´ë ‡ê²Œ **ì´ì „ ë‹¨ê³„ì˜ ì •ë³´(ë°”í†µ)ë¥¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì „ë‹¬**í•˜ëŠ” êµ¬ì¡°ê°€ RNNì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48aaeee",
   "metadata": {},
   "source": [
    "### PyTorchë¡œ RNN ë§›ë³´ê¸°\n",
    "ê¸°ë³¸ì ì¸ ì…ë ¥ê³¼ ì¶œë ¥ í˜•íƒœ(Shape)ë¥¼ ì•Œì•„ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c762480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 1. ì„¤ì •ê°’ ì •ì˜\n",
    "batch_size = 2      # í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì¥ ê°œìˆ˜ (2ê°œ)\n",
    "seq_len = 3         # ë¬¸ì¥ì˜ ê¸¸ì´ (ë‹¨ì–´ 3ê°œì§œë¦¬ ë¬¸ì¥)\n",
    "input_size = 4      # ë‹¨ì–´ í•˜ë‚˜ë¥¼ í‘œí˜„í•˜ëŠ” ìˆ«ìì˜ ê°œìˆ˜ (Feature ì°¨ì›)\n",
    "hidden_size = 5     # ê¸°ì–µ ì¥ì†Œ(Hidden State)ì˜ í¬ê¸° (5ê°œì˜ ìˆ«ìë¡œ ê¸°ì–µ)\n",
    "\n",
    "# 2. ê°€ì§œ ì…ë ¥ ë°ì´í„° ë§Œë“¤ê¸° (ëœë¤ê°’)\n",
    "# Shape: (ë°°ì¹˜ í¬ê¸°, ë¬¸ì¥ ê¸¸ì´, ë‹¨ì–´ ë²¡í„° í¬ê¸°) -> (2, 3, 4)\n",
    "x = torch.randn(batch_size, seq_len, input_size)\n",
    "print(\"ì…ë ¥ ë°ì´í„° í˜•íƒœ(Shape):\", x.shape)\n",
    "\n",
    "# 3. RNN ëª¨ë¸ ë§Œë“¤ê¸°\n",
    "# batch_first=True: ì…ë ¥ì˜ ì²« ë²ˆì§¸ ì°¨ì›ì´ Batch Sizeì„ì„ ëª…ì‹œ\n",
    "rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "# 4. ì‹¤í–‰ (Forward)\n",
    "# output: ë§¤ ì‹œì ì˜ ì¶œë ¥ (ê¸°ì–µì˜ ê¸°ë¡ë“¤)\n",
    "# hidden: ë§¨ ë§ˆì§€ë§‰ ì‹œì ì˜ ì€ë‹‰ ìƒíƒœ (ìµœì¢… ìš”ì•½ë³¸)\n",
    "output, hidden = rnn(x)\n",
    "\n",
    "print(\"ì „ì²´ ì¶œë ¥(Output) í˜•íƒœ:\", output.shape)  # expected: (2, 3, 5) -> (Batch, Seq, Hidden)\n",
    "print(\"ë§ˆì§€ë§‰ ê¸°ì–µ(Hidden) í˜•íƒœ:\", hidden.shape) # expected: (1, 2, 5) -> (Layer, Batch, Hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4ccdd",
   "metadata": {},
   "source": [
    "## 3. ì‹¤ìŠµ: IMDB ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„\n",
    "\n",
    "ì˜í™” ë¦¬ë·°ë¥¼ ì½ê³  ì´ ì˜í™”ê°€ **ê¸ì •(Positive, 1)**ì¸ì§€ **ë¶€ì •(Negative, 0)**ì¸ì§€ ë§ì¶”ëŠ” AIë¥¼ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "- **ì…ë ¥**: ì˜í™” ë¦¬ë·° í…ìŠ¤íŠ¸ (ì˜ì–´)\n",
    "- **ì¶œë ¥**: 0 ë˜ëŠ” 1 (ì´ì§„ ë¶„ë¥˜)\n",
    "- **íŠ¹ì§•**: ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ 300ê°œ(`vocab_size`)ë¡œ ì œí•œí•´ì„œ ì‹¤ìŠµí•©ë‹ˆë‹¤ (ë©”ëª¨ë¦¬ ì ˆì•½)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3096c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "vocab_size = 300  # ê°€ì¥ ìì£¼ ë‚˜ì˜¤ëŠ” ë‹¨ì–´ 300ê°œë§Œ ì“°ê² ë‹¤! (ë‚˜ë¨¸ì§€ëŠ” ë¬´ì‹œ)\n",
    "\n",
    "# ë°ì´í„° ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ\n",
    "# X: ë¦¬ë·° ë‚´ìš©(ìˆ«ì ë¦¬ìŠ¤íŠ¸), y: ì •ë‹µ ë¼ë²¨(0/1)\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„° ê°œìˆ˜: {len(X_train)}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°œìˆ˜: {len(X_test)}\")\n",
    "\n",
    "# ë°ì´í„° ì¡°ê¸ˆë§Œ ì“°ê¸° (ì†ë„ë¥¼ ìœ„í•´)\n",
    "# í•™ìŠµ 25000ê°œ, í…ŒìŠ¤íŠ¸ 10000ê°œ ê·¸ëŒ€ë¡œ ì‚¬ìš©\n",
    "# í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ ìŠ¬ë¼ì´ì‹±ìœ¼ë¡œ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13ba04",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ì‚´í´ë³´ê¸°\n",
    "ì»´í“¨í„°ëŠ” ê¸€ìë¥¼ ëª¨ë¥´ê¸° ë•Œë¬¸ì—, ì´ë¯¸ **ìˆ«ì(Index)**ë¡œ ë°”ë€Œì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "ì˜ˆë¥¼ ë“¤ì–´ 1ì€ 'ì‹œì‘', 2ëŠ” 'OOV' ë“±ì„ ì˜ë¯¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675206b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ì²« ë²ˆì§¸ ë¦¬ë·°(ìˆ«ì):\", X_train[0])\n",
    "print(\"ì²« ë²ˆì§¸ ë¦¬ë·° ê¸¸ì´:\", len(X_train[0]))\n",
    "print(\"ì²« ë²ˆì§¸ ì •ë‹µ:\", y_train[0]) # 1ì´ë©´ ê¸ì •, 0ì´ë©´ ë¶€ì •"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7185e221",
   "metadata": {},
   "source": [
    "### í…ì„œ(Tensor)ë¡œ ë³€í™˜\n",
    "ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì¸ PyTorchì—ì„œ ì“°ë ¤ë©´ ë¦¬ìŠ¤íŠ¸ë¥¼ `Tensor`ë¡œ ë°”ê¿”ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf7df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ë¦¬ìŠ¤íŠ¸(List) -> í…ì„œ(Tensor) ë³€í™˜\n",
    "# í•˜ë‚˜í•˜ë‚˜ ë³€í™˜í•´ì„œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ìŠµë‹ˆë‹¤.\n",
    "X_train = [torch.tensor(seq, dtype=torch.long) for seq in X_train]\n",
    "X_test = [torch.tensor(seq, dtype=torch.long) for seq in X_test]\n",
    "\n",
    "# ì •ë‹µ(Label)ë„ í…ì„œë¡œ ë³€í™˜ (ì‹¤ìˆ˜í˜• Float)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float)\n",
    "\n",
    "print(\"ë³€í™˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040f4cb",
   "metadata": {},
   "source": [
    "### íŒ¨ë”©(Padding): ê¸¸ì´ ë§ì¶”ê¸°\n",
    "ë¦¬ë·°ë§ˆë‹¤ ê¸¸ì´ê°€ ì œê°ê°ì…ë‹ˆë‹¤. ì–´ë–¤ ê±´ 10ë‹¨ì–´, ì–´ë–¤ ê±´ 100ë‹¨ì–´...\n",
    "ê¸°ê³„í•™ìŠµì„ ìœ„í•´ì„  ê¸¸ì´ë¥¼ ë˜‘ê°™ì´ ë§ì¶°ì•¼ í•©ë‹ˆë‹¤. (ì§ì‚¬ê°í˜• ë§Œë“¤ê¸°)\n",
    "\n",
    "> **ë¹„ìœ  (í…ŒíŠ¸ë¦¬ìŠ¤)**: ë¹ˆ ê³µê°„ì„ 0ìœ¼ë¡œ ì±„ì›Œì„œ ë„¤ëª¨ ë°˜ë“¯í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "- ì§§ìœ¼ë©´ -> 0ì„ ì±„ìš´ë‹¤ (`Padding`)\n",
    "- ë„ˆë¬´ ê¸¸ë©´ -> ìë¥¸ë‹¤ (`Truncating`)\n",
    "- ì—¬ê¸°ì„  ê¸¸ì´ë¥¼ **100**ìœ¼ë¡œ í†µì¼í•˜ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72500fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "max_len = 100 # ëª©í‘œ ê¸¸ì´\n",
    "\n",
    "def pad_sequences(sequences, max_len):\n",
    "    padded_list = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_len:\n",
    "            # ê¸¸ì´ê°€ ì§§ìœ¼ë©´ ë’¤ì— 0ì„ ì±„ì›€ (padí•¨ìˆ˜: (ì™¼ìª½ì±„ì›€, ì˜¤ë¥¸ìª½ì±„ì›€))\n",
    "            seq = F.pad(seq, (0, max_len - len(seq)), value=0)\n",
    "        else:\n",
    "            # ê¸¸ì´ê°€ ê¸¸ë©´ ì•ë¶€ë¶„ë¶€í„° 100ê°œë§Œ ìë¦„\n",
    "            seq = seq[:max_len]\n",
    "        padded_list.append(seq)\n",
    "    # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ í° í…ì„œë¡œ í•©ì¹¨ (Stack)\n",
    "    return torch.stack(padded_list)\n",
    "\n",
    "X_train_padded = pad_sequences(X_train, max_len)\n",
    "X_test_padded = pad_sequences(X_test, max_len)\n",
    "\n",
    "print(\"íŒ¨ë”© í›„ í˜•íƒœ:\", X_train_padded.shape) # (25000, 100) -> 2ë§Œ5ì²œê°œ ë¬¸ì¥, ê° 100ë‹¨ì–´"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a63a9b",
   "metadata": {},
   "source": [
    "### ì›-í•« ì¸ì½”ë”© (One-Hot Encoding)\n",
    "ìˆ«ì 1, 2, 3ì€ í¬ê¸° ì°¨ì´ê°€ ìˆì§€ë§Œ, ë‹¨ì–´ ID 1, 2, 3ì€ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
    "ê·¸ë˜ì„œ ì´ë¥¼ ë…ë¦½ì ì¸ ë²¡í„°ë¡œ ë°”ê¿”ì¤ë‹ˆë‹¤.\n",
    "\n",
    "> **ì£¼ì˜**: ì›-í•« ì¸ì½”ë”©ì€ 0ì´ ë„ˆë¬´ ë§ì•„ì ¸ì„œ ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ì°¨ì§€í•©ë‹ˆë‹¤. ì‹¤ë¬´ì—ì„  **ì„ë² ë”©(Embedding)**ì„ ì“°ì§€ë§Œ, ì—¬ê¸°ì„  ì›ë¦¬ë¥¼ ë°°ìš°ê¸° ìœ„í•´ ì‚¬ìš©í•´ë´…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93677c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (ìƒ˜í”Œìˆ˜, ê¸¸ì´) -> (ìƒ˜í”Œìˆ˜, ê¸¸ì´, ë‹¨ì–´ì¥í¬ê¸°)\n",
    "# 300ê°œì˜ ì¹¸ ì¤‘ í•˜ë‚˜ë§Œ 1ì´ê³  ë‚˜ë¨¸ì§„ 0ì¸ ë²¡í„°ë¡œ ë³€í™˜\n",
    "X_train_onehot = F.one_hot(X_train_padded, num_classes=vocab_size).float()\n",
    "X_test_onehot = F.one_hot(X_test_padded, num_classes=vocab_size).float()\n",
    "\n",
    "print(\"ì›-í•« ë³€í™˜ í›„ í˜•íƒœ:\", X_train_onehot.shape)\n",
    "# (25000, 100, 300) -> ë°ì´í„°ê°€ ë§¤ìš° ì»¤ì¡ŒìŠµë‹ˆë‹¤!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6607f9",
   "metadata": {},
   "source": [
    "## 4. ëª¨ë¸ ì„¤ê³„ (Design)\n",
    "\n",
    "1. **RNN ì¸µ**: ë‹¨ì–´ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì½ì–´ì„œ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ì••ì¶•(Hidden State)í•©ë‹ˆë‹¤.\n",
    "2. **Linear ì¸µ (FC)**: ì••ì¶•ëœ ì˜ë¯¸ë¥¼ ë³´ê³  0(ë¶€ì •)ì¸ì§€ 1(ê¸ì •)ì¸ì§€ íŒë‹¨ ì ìˆ˜ë¥¼ ëƒ…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IMDBSentimentRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # 1. RNN ë ˆì´ì–´\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_dim,   # ë“¤ì–´ì˜¤ëŠ” ë²¡í„° í¬ê¸° (300)\n",
    "            hidden_size=hidden_dim, # ê¸°ì–µ ì¥ì†Œ í¬ê¸° (ë§ˆìŒëŒ€ë¡œ ì„¤ì •, ì—¬ê¸°ì„  8)\n",
    "            batch_first=True        # ì²« ë²ˆì§¸ ì°¨ì›ì´ batch_size\n",
    "        )\n",
    "        # 2. ê²°ë¡  ë‚´ëŠ” ë ˆì´ì–´ (Fully Connected)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim) # 8ê°œ íŠ¹ì§• -> 1ê°œ ì ìˆ˜\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (Batch, 100, 300)\n",
    "        \n",
    "        # RNN í†µê³¼\n",
    "        # output: ëª¨ë“  ì‹œì ì˜ ìƒíƒœ\n",
    "        # hidden: ë§ˆì§€ë§‰ ì‹œì ì˜ ìƒíƒœ (ìµœì¢… ìš”ì•½ë³¸)\n",
    "        output, hidden = self.rnn(x)\n",
    "        \n",
    "        # ìš°ë¦¬ëŠ” 'ë§ˆì§€ë§‰ ìš”ì•½ë³¸'ë§Œ ìˆìœ¼ë©´ ë©ë‹ˆë‹¤.\n",
    "        # hidden shape: (1, Batch, Hidden) -> squeeze -> (Batch, Hidden)\n",
    "        last_hidden = hidden.squeeze(0)\n",
    "        \n",
    "        # ì ìˆ˜ ê³„ì‚°\n",
    "        logit = self.fc(last_hidden)\n",
    "        return logit\n",
    "\n",
    "input_dim = vocab_size # 300\n",
    "hidden_dim = 8         # 8\n",
    "output_dim = 1         # 1 (ê¸ì •/ë¶€ì • ì ìˆ˜)\n",
    "\n",
    "model = IMDBSentimentRNN(input_dim, hidden_dim, output_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff9a78b",
   "metadata": {},
   "source": [
    "## 5. í•™ìŠµ ì¤€ë¹„\n",
    "- **ë°ì´í„° ë¡œë”(DataLoader)**: ë°ì´í„°ë¥¼ ë°°ì¹˜(Batch) ë‹¨ìœ„ë¡œ ë¬¶ì–´ì„œ í•˜ë‚˜ì”© êº¼ë‚´ì¤ë‹ˆë‹¤.\n",
    "- **ì†ì‹¤í•¨ìˆ˜(Loss)**: í‹€ë¦° ì •ë„ë¥¼ ê³„ì‚° (BCEWithLogitsLoss: ì´ì§„ ë¶„ë¥˜ìš©)\n",
    "- **ìµœì í™”(Optimizer)**: ì˜¤ë‹µ ë…¸íŠ¸(Loss)ë¥¼ ë³´ê³  ëª¨ë¸ì„ ìˆ˜ì • (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455292e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import torch.optim as optim\n",
    "\n",
    "# 1. ë°ì´í„°ì…‹ ë§Œë“¤ê¸° (ì…ë ¥ê³¼ ì •ë‹µì„ ë¬¶ìŒ)\n",
    "# ì •ë‹µ ë°ì´í„°(y) ì°¨ì› ë§ì¶”ê¸°: (25000) -> (25000, 1)\n",
    "y_train = y_train.unsqueeze(1)\n",
    "y_test = y_test.unsqueeze(1)\n",
    "\n",
    "dataset = TensorDataset(X_train_onehot, y_train)\n",
    "\n",
    "# 2. í•™ìŠµìš©(Train) / ê²€ì¦ìš©(Val) ë‚˜ëˆ„ê¸° (8:2)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 3. ë¡œë” ìƒì„± (Batch Size=64)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 4. ì¥ì¹˜ ì„¤ì • (GPU ìˆìœ¼ë©´ ì‚¬ìš©)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# 5. ë„êµ¬ ì„¤ì •\n",
    "criterion = nn.BCEWithLogitsLoss() # ì´ì§„ ë¶„ë¥˜ ì†ì‹¤í•¨ìˆ˜\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # ì„ ìƒë‹˜(Adam)\n",
    "\n",
    "print(\"í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ! Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c80cdf",
   "metadata": {},
   "source": [
    "## 6. í•™ìŠµ ì‹œì‘! (Train Loop)\n",
    "ëª¨ë¸ì´ ë¬¸ì œë¥¼ í’€ê³ , ì±„ì  ë°›ê³ , ê³µë¶€í•˜ëŠ” ê³¼ì •ì„ ë°˜ë³µí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8f2b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5  # êµê³¼ì„œ 5ë²ˆ ë³´ê¸° (ë„ˆë¬´ ë§ì´ í•˜ë©´ ì‹œê°„ ì˜¤ë˜ ê±¸ë¦¼)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train() # í•™ìŠµ ëª¨ë“œ ì „í™˜\n",
    "    train_loss = 0\n",
    "    \n",
    "    # tqdmìœ¼ë¡œ ì§„í–‰ìƒí™© ë°” í‘œì‹œ\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # 1. ì´ˆê¸°í™” (ì´ì „ ê¸°ì–µ ì§€ìš°ê¸°)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 2. ë¬¸ì œ í’€ê¸° (Forward)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 3. ì±„ì  (Loss ê³„ì‚°)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # 4. ë³µìŠµ (Backward - ê¸°ìš¸ê¸° ê³„ì‚°)\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. ìˆ˜ì • (Step - íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # í‰ê·  ì ìˆ˜ ì¶œë ¥\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} ì™„ë£Œ! í‰ê·  ì†ì‹¤(Loss): {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029c1d68",
   "metadata": {},
   "source": [
    "## 7. í‰ê°€ (Test)\n",
    "í•™ìŠµì— ì“°ì§€ ì•Šì€(Test) ë°ì´í„°ë¡œ ì§„ì§œ ì‹¤ë ¥ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81aa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval() # í‰ê°€ ëª¨ë“œ (ê³µë¶€ ì¤‘ë‹¨)\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "test_loader = DataLoader(TensorDataset(X_test_onehot, y_test), batch_size=batch_size)\n",
    "\n",
    "with torch.no_grad(): # í‰ê°€í•  ë• ìˆ˜ì •í•˜ì§€ ì•ŠìŒ\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # í™•ë¥ ë¡œ ë³€í™˜ (Sigmoid)\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        \n",
    "        # 0.5ë³´ë‹¤ í¬ë©´ 1(ê¸ì •), ì•„ë‹ˆë©´ 0(ë¶€ì •)\n",
    "        predicted = (probs > 0.5).float()\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì •í™•ë„: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
