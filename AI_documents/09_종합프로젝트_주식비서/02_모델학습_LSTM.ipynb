{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02. ëª¨ë¸ í•™ìŠµ: ë¯¸ë˜ ì˜ˆì¸¡í•˜ê¸° (LSTM) ğŸ”®\n",
                "\n",
                "> **ëª©í‘œ**: ì§€ë‚œ 10ì¼ê°„ì˜ ì£¼ê°€ íë¦„ì„ ë³´ê³ , **\"ë‚´ì¼ ì˜¤ë¥¼ê¹Œ?\"**ë¥¼ ë§íˆëŠ” ì¸ê³µì§€ëŠ¥ì„ ë§Œë“­ë‹ˆë‹¤. ì‹œê³„ì—´(ì‹œê°„ ìˆœì„œê°€ ìˆëŠ”) ë°ì´í„°ì— ê°€ì¥ ê°•í•œ **LSTM** ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
                "\n",
                "## 1. ë°ì´í„° ì¤€ë¹„ (ì¬ë£Œ ì†ì§ˆ)\n",
                "ì €ì¥í•´ë‘” ì‚¼ì„±ì „ì ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. AIëŠ” í° ìˆ«ì(80,000ì›)ë¥¼ ì‹«ì–´í•˜ë¯€ë¡œ, **0ê³¼ 1 ì‚¬ì´ë¡œ ì••ì¶•(ìŠ¤ì¼€ì¼ë§)**í•´ì¤˜ì•¼ í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "\n",
                "# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
                "df = pd.read_csv(\"samsung_stock.csv\", index_col='Date', parse_dates=True)\n",
                "data = df[['Close']].values # 'ì¢…ê°€'ë§Œ ì‚¬ìš©\n",
                "\n",
                "# 2. ìŠ¤ì¼€ì¼ë§ (0~1 ì‚¬ì´ë¡œ ë³€í™˜)\n",
                "scaler = MinMaxScaler(feature_range=(0, 1))\n",
                "scaled_data = scaler.fit_transform(data)\n",
                "\n",
                "print(\"ë°ì´í„° ë³€í™˜ ì™„ë£Œ:\", scaled_data[:5])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ë°ì´í„°ì…‹ ë§Œë“¤ê¸° (ë¬¸ì œì§‘ ë§Œë“¤ê¸°)\n",
                "LSTMì€ **\"ê³¼ê±°ì˜ íŒ¨í„´\"**ì„ ë³´ê³  ë¯¸ë˜ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
                "\n",
                "**ë¹„ìœ **:\n",
                "- **ë¬¸ì œ**: [1ì¼ì°¨, 2ì¼ì°¨, ..., 10ì¼ì°¨ ê°€ê²©]\n",
                "- **ì •ë‹µ**: [11ì¼ì°¨ ê°€ê²©]\n",
                "\n",
                "ì´ë ‡ê²Œ 10ì¼ ì¹˜ë¥¼ ë¬¶ì–´ì„œ ë¬¸ì œ(X)ë¡œ ì£¼ê³ , ë‹¤ìŒ ë‚ ì„ ì •ë‹µ(y)ìœ¼ë¡œ ì£¼ëŠ” ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_dataset(dataset, window_size=10):\n",
                "    X, y = [], []\n",
                "    for i in range(len(dataset) - window_size):\n",
                "        X.append(dataset[i : i + window_size])\n",
                "        y.append(dataset[i + window_size])\n",
                "    return np.array(X), np.array(y)\n",
                "\n",
                "window_size = 10\n",
                "X, y = create_dataset(scaled_data, window_size)\n",
                "\n",
                "# í›ˆë ¨ìš©/í…ŒìŠ¤íŠ¸ìš© ë‚˜ëˆ„ê¸° (80% í›ˆë ¨, 20% í…ŒìŠ¤íŠ¸)\n",
                "split = int(len(X) * 0.8)\n",
                "X_train, X_test = X[:split], X[split:]\n",
                "y_train, y_test = y[:split], y[split:]\n",
                "\n",
                "print(\"í›ˆë ¨ ë°ì´í„° ê°œìˆ˜:\", X_train.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. LSTM ëª¨ë¸ ë§Œë“¤ê¸° (ë‡Œ êµ¬ì¡° ì„¤ê³„)\n",
                "ì¼€ë¼ìŠ¤(Keras)ë¥¼ ì‚¬ìš©í•˜ë©´ ë¸”ë¡ ìŒ“ë“¯ì´ ì‰½ê²Œ ëª¨ë¸ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Dense, LSTM\n",
                "\n",
                "model = Sequential()\n",
                "# 1. LSTM ì¸µ (ê¸°ì–µë ¥ ì„¸í¬)\n",
                "model.add(LSTM(50, return_sequences=False, input_shape=(window_size, 1)))\n",
                "# 2. ì¶œë ¥ ì¸µ (ì˜ˆì¸¡ê°’ ë‚´ë±‰ê¸°)\n",
                "model.add(Dense(1))\n",
                "\n",
                "model.compile(optimizer='adam', loss='mse')\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. í•™ìŠµ ì‹œì‘ (ê³µë¶€í•´!)\n",
                "# epochs=20: ë¬¸ì œì§‘ì„ 20ë°”í€´ ë°˜ë³µí•´ì„œ í’€ê¸°\n",
                "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. ê²°ê³¼ í™•ì¸ ë° ì €ì¥\n",
                "ì–¼ë§ˆë‚˜ ì˜ ë§íˆëŠ”ì§€ ê·¸ë˜í”„ë¡œ ê·¸ë ¤ë³´ê³ , ì˜ ë§Œë“  ëª¨ë¸ì€ íŒŒì¼(`models/my_stock_model.h5`)ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# ì˜ˆì¸¡í•˜ê¸°\n",
                "predictions = model.predict(X_test)\n",
                "\n",
                "# ìŠ¤ì¼€ì¼ë§ì„ ì›ë˜ ê°€ê²©ìœ¼ë¡œ ë˜ëŒë¦¬ê¸°\n",
                "actual_prices = scaler.inverse_transform(y_test)\n",
                "predicted_prices = scaler.inverse_transform(predictions)\n",
                "\n",
                "# ê·¸ë˜í”„ ê·¸ë¦¬ê¸°\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(actual_prices, label='Actual Price', color='blue')\n",
                "plt.plot(predicted_prices, label='Predicted Price', color='red')\n",
                "plt.title('Samsung Electronics Price Prediction')\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# ëª¨ë¸ ì €ì¥\n",
                "model.save(\"models/my_stock_model.h5\")\n",
                "print(\"ëª¨ë¸ ì €ì¥ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. âš”ï¸ ë„ì „! ì‹¤ìŠµ ë¯¸ì…˜\n",
                "**ë¯¸ì…˜: í•™ìŠµ íšŸìˆ˜(epochs)ë¥¼ 50ìœ¼ë¡œ ëŠ˜ë ¤ì„œ ë‹¤ì‹œ í•™ìŠµì‹œì¼œë³´ì„¸ìš”. ê²°ê³¼ê°€ ë” ì¢‹ì•„ì§€ë‚˜ìš”?**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ì—¬ê¸°ì— ì½”ë“œë¥¼ ìˆ˜ì •í•´ì„œ ì‘ì„±í•´ë³´ì„¸ìš”\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}