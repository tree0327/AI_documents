{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9241cd3c",
   "metadata": {},
   "source": [
    "# 문서 벡터화 Document Vectorization\n",
    "- BOW\n",
    "- TF-IDF\n",
    "- DTM / TDM\n",
    "\n",
    "## BOW Bag of Words\n",
    "CountVectorizer클래스를 통해 텍스트를 토큰화하고, 단어빈도수 기반으로 특성벡터를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3cd894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'I love my dog.',\n",
    "    'I love my cat.',\n",
    "    'I love my dog and love my cat.',\n",
    "    'You love my dog!',\n",
    "    'Do you think my dog is amazing?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87cba230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 22 stored elements and shape (5, 10)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 객체 생성\n",
    "vectorizer = CountVectorizer() # 객체 생성\n",
    "features = vectorizer.fit_transform(sentences)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2b0767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 2, 2, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 1, 0, 1, 1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 값 확인\n",
    "features.toarray() # 희소행렬을 Numpy 2차원배열(밀집 배열 = dense array)로 바꿔서 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36649285",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['amazing', 'and', 'cat', 'do', 'dog', 'is', 'love', 'my', 'think',\n",
       "       'you'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names_out() # 학습된 vocabulary의 피처명 목록\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e667626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>and</th>\n",
       "      <th>cat</th>\n",
       "      <th>do</th>\n",
       "      <th>dog</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>my</th>\n",
       "      <th>think</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       amazing  and  cat  do  dog  is  love  my  think  you\n",
       "sent1        0    0    0   0    1   0     1   1      0    0\n",
       "sent2        0    0    1   0    0   0     1   1      0    0\n",
       "sent3        0    1    1   0    1   0     2   2      0    0\n",
       "sent4        0    0    0   0    1   0     1   1      0    1\n",
       "sent5        1    0    0   1    1   1     0   1      1    1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "bow_df = pd.DataFrame(\n",
    "    features.toarray(),      # 희소행렬을 dense 배열로 바꿔서 생성\n",
    "    columns = feature_names, # 단어사전(피처명)\n",
    "    index = ['sent1', 'sent2', 'sent3', 'sent4', 'sent5' ] # 행 이름 지정\n",
    ")\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764b35f",
   "metadata": {},
   "source": [
    "features가 커지면 toarray()로 바꿀시 메모리를 많이 사용해서, 큰 데이터에서는 이룹만 확인하거나 희소형태를 유지하는 방식을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36f50900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I love my dog.</th>\n",
       "      <th>I love my cat.</th>\n",
       "      <th>I love my dog and love my cat.</th>\n",
       "      <th>You love my dog!</th>\n",
       "      <th>Do you think my dog is amazing?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I love my dog.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.870388</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.436436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I love my cat.</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.870388</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.218218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I love my dog and love my cat.</th>\n",
       "      <td>0.870388</td>\n",
       "      <td>0.870388</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.753778</td>\n",
       "      <td>0.341882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You love my dog!</th>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.753778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.566947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do you think my dog is amazing?</th>\n",
       "      <td>0.436436</td>\n",
       "      <td>0.218218</td>\n",
       "      <td>0.341882</td>\n",
       "      <td>0.566947</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 I love my dog.  I love my cat.  \\\n",
       "I love my dog.                         1.000000        0.666667   \n",
       "I love my cat.                         0.666667        1.000000   \n",
       "I love my dog and love my cat.         0.870388        0.870388   \n",
       "You love my dog!                       0.866025        0.577350   \n",
       "Do you think my dog is amazing?        0.436436        0.218218   \n",
       "\n",
       "                                 I love my dog and love my cat.  \\\n",
       "I love my dog.                                         0.870388   \n",
       "I love my cat.                                         0.870388   \n",
       "I love my dog and love my cat.                         1.000000   \n",
       "You love my dog!                                       0.753778   \n",
       "Do you think my dog is amazing?                        0.341882   \n",
       "\n",
       "                                 You love my dog!  \\\n",
       "I love my dog.                           0.866025   \n",
       "I love my cat.                           0.577350   \n",
       "I love my dog and love my cat.           0.753778   \n",
       "You love my dog!                         1.000000   \n",
       "Do you think my dog is amazing?          0.566947   \n",
       "\n",
       "                                 Do you think my dog is amazing?  \n",
       "I love my dog.                                          0.436436  \n",
       "I love my cat.                                          0.218218  \n",
       "I love my dog and love my cat.                          0.341882  \n",
       "You love my dog!                                        0.566947  \n",
       "Do you think my dog is amazing?                         1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "bow_sim = cosine_similarity(bow_df)\n",
    "bow_sim_df = pd.DataFrame(\n",
    "    bow_sim,             # 유사도 결과를 데이터로 사용\n",
    "    columns = sentences, # 열은 문장(비교 대상)\n",
    "    index = sentences    # 행은 문장 (기준)\n",
    ")\n",
    "\n",
    "bow_sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26de7518",
   "metadata": {},
   "source": [
    "## DTM | TDM\n",
    "- DTM Document-Term Matrix 문서별 용어 행렬\n",
    "- TDM Term-Document Matrix 용어별 문서 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfc22ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>and</th>\n",
       "      <th>cat</th>\n",
       "      <th>do</th>\n",
       "      <th>dog</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>my</th>\n",
       "      <th>think</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       amazing  and  cat  do  dog  is  love  my  think  you\n",
       "sent1        0    0    0   0    1   0     1   1      0    0\n",
       "sent2        0    0    1   0    0   0     1   1      0    0\n",
       "sent3        0    1    1   0    1   0     2   2      0    0\n",
       "sent4        0    0    0   0    1   0     1   1      0    1\n",
       "sent5        1    0    0   1    1   1     0   1      1    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DTM : BoW 결과를 문서-단어 행렬(DataFrame)로 구성\n",
    "dtm = pd.DataFrame(\n",
    "    features.toarray(),\n",
    "    columns = feature_names,\n",
    "    index = ['sent1', 'sent2', 'sent3', 'sent4', 'sent5' ]\n",
    ")\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d949c822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>sent3</th>\n",
       "      <th>sent4</th>\n",
       "      <th>sent5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>think</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sent1  sent2  sent3  sent4  sent5\n",
       "amazing      0      0      0      0      1\n",
       "and          0      0      1      0      0\n",
       "cat          0      1      1      0      0\n",
       "do           0      0      0      0      1\n",
       "dog          1      0      1      1      1\n",
       "is           0      0      0      0      1\n",
       "love         1      1      2      1      0\n",
       "my           1      1      2      1      1\n",
       "think        0      0      0      0      1\n",
       "you          0      0      0      1      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TDM : DTM을 전치해서 단어-문서 행렬로 변환. 단어를 기준으로 문서별 빈도를 비교/분석\n",
    "tdm = dtm.transpose()  # (문서 x 단어) -> (단어 x 문서) TDM으로 전치\n",
    "tdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc20e3b",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "`TfidfVectorizer`의 계산은 TF-IDF(Term Frequency-Inverse Document Frequency)라는 지표를 사용한다.\n",
    "\n",
    "이는 각 단어의 중요도를 고려하여 문서 내에서의 가중치를 계산하는 방식이다.\n",
    "\n",
    "**용어**\n",
    "- $tf(t, d)$: 특정 단어 $t$가 문서 $d$에서 등장한 횟수 (Term Frequency)\n",
    "- $df(t)$: 특정 단어 $t$가 등장한 문서의 수 (Document Frequency)\n",
    "- $N$: 전체 문서의 수\n",
    "\n",
    "**TF (Term Frequency)**\n",
    "단어 $t$의 문서 $d$에서의 빈도를 계산하는데, 가장 일반적인 방법은 해당 단어의 단순 빈도로 정의한다.\n",
    "\n",
    "$\n",
    "tf(t, d) = \\frac{\\text{단어 } t \\text{의 문서 } d \\text{ 내 등장 횟수}}{\\text{문서 } d \\text{의 전체 단어 수}}\n",
    "$\n",
    "\n",
    "**IDF (Inverse Document Frequency)**\n",
    "단어가 전체 문서에서 얼마나 중요한지를 계산한다. 특정 단어가 많은 문서에서 등장하면, 이 단어는 중요도가 낮아진다. 이를 반영하기 위해 아래와 같은 식을 사용한다:\n",
    "\n",
    "$\n",
    "idf(t) = \\log\\left(\\frac{1 + N}{1 + df(t)}\\right) + 1\n",
    "$\n",
    "\n",
    "여기서 $1$을 더하는 이유는, 특정 단어가 모든 문서에 등장하지 않을 경우 $df(t) = 0$이 되어, 분모가 $0$이 되는 것을 방지하기 위함이다.\n",
    "\n",
    "예를 들어, $\\log(5/(1+1))$과 $\\log(5/(1+2))$를 계산하면, 각각 $0.3979$와 $0.2218$이 된다.\n",
    "\n",
    "**TF-IDF 계산**\n",
    "위의 TF와 IDF를 결합하여 TF-IDF 가중치를 계산한다:\n",
    "\n",
    "$\n",
    "\\text{tf-idf}(t, d) = tf(t, d) \\times idf(t)\n",
    "$\n",
    "\n",
    "**TfidfVectorizer의 주요 파라미터**\n",
    "<table border=\"1\" cellpadding=\"5\" cellspacing=\"0\">\n",
    "  <tr style=\"background-color: #f2f2f2;\">\n",
    "    <th>Parameter</th>\n",
    "    <th>Description</th>\n",
    "    <th>Default Value</th>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #675202;\">\n",
    "    <td><b>max_df</b></td>\n",
    "    <td>문서의 비율 값으로서, 해당 비율 이상 나타나는 단어를 무시한다. <br> 예를 들어, max_df=0.8이면, 80% 이상의 문서에서 나타나는 단어는 제외된다.</td>\n",
    "    <td>1.0</td>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #675202;\">\n",
    "    <td><b>min_df</b></td>\n",
    "    <td>문서의 비율 값 또는 정수로, 해당 비율 이하 나타나는 단어를 무시한다. <br> 예를 들어, min_df=2이면, 두 개 이하의 문서에서만 나타나는 단어는 제외된다.</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #675202;\">\n",
    "    <td><b>ngram_range</b></td>\n",
    "    <td>(min_n, max_n) 형식으로, 사용할 n-gram의 범위를 정의한다. <br> 예를 들어, (1, 2)로 설정하면 unigram과 bigram을 고려한다.</td>\n",
    "    <td>(1, 1)</td>\n",
    "  </tr>\n",
    "  <tr style=\"background-color: #675202;\">\n",
    "    <td>stop_words</td>\n",
    "    <td>불용어를 지정할 수 있다. \"english\"로 설정하면 영어 불용어를 사용한다.</td>\n",
    "    <td>None</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>max_features</td>\n",
    "    <td>벡터화할 때 고려할 최대 단어 수를 설정한다. 빈도순으로 상위 단어들이 선택된다.</td>\n",
    "    <td>None</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>use_idf</td>\n",
    "    <td>IDF(역문서 빈도)를 사용할지 여부를 지정한다. False로 설정하면 단순히 TF 값만 사용한다.</td>\n",
    "    <td>True</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>smooth_idf</td>\n",
    "    <td>IDF 계산 시, 0으로 나누는 것을 피하기 위해 추가적인 smoothing을 수행한다.</td>\n",
    "    <td>True</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>sublinear_tf</td>\n",
    "    <td>TF 값에 대해 sublinear scaling (1 + log(tf))를 적용할지 지정한다.</td>\n",
    "    <td>False</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04519b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 22 stored elements and shape (5, 10)>\n",
      "  Coords\tValues\n",
      "  (0, 6)\t0.6068561362933035\n",
      "  (0, 7)\t0.5132750331803866\n",
      "  (0, 4)\t0.6068561362933035\n",
      "  (1, 6)\t0.5152898800248592\n",
      "  (1, 7)\t0.43582888010783327\n",
      "  (1, 2)\t0.7379224395611763\n",
      "  (2, 6)\t0.5533643125368353\n",
      "  (2, 7)\t0.4680319912607929\n",
      "  (2, 4)\t0.27668215626841763\n",
      "  (2, 2)\t0.3962235232075343\n",
      "  (2, 1)\t0.4911088441748528\n",
      "  (3, 6)\t0.4580537876334307\n",
      "  (3, 7)\t0.3874189597587254\n",
      "  (3, 4)\t0.4580537876334307\n",
      "  (3, 9)\t0.6559573194109529\n",
      "  (4, 7)\t0.20905444571530132\n",
      "  (4, 4)\t0.24716957771281237\n",
      "  (4, 9)\t0.3539599453463846\n",
      "  (4, 3)\t0.4387242287788317\n",
      "  (4, 8)\t0.4387242287788317\n",
      "  (4, 5)\t0.4387242287788317\n",
      "  (4, 0)\t0.4387242287788317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.60685614,\n",
       "        0.        , 0.60685614, 0.51327503, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.73792244, 0.        , 0.        ,\n",
       "        0.        , 0.51528988, 0.43582888, 0.        , 0.        ],\n",
       "       [0.        , 0.49110884, 0.39622352, 0.        , 0.27668216,\n",
       "        0.        , 0.55336431, 0.46803199, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.45805379,\n",
       "        0.        , 0.45805379, 0.38741896, 0.        , 0.65595732],\n",
       "       [0.43872423, 0.        , 0.        , 0.43872423, 0.24716958,\n",
       "        0.43872423, 0.        , 0.20905445, 0.43872423, 0.35395995]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF 백터라이저 : 단어 빈도를 중요도(TF-IDF)로 가중한 문서-단어 행렬 생성\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "features = tfidf_vectorizer.fit_transform(sentences) # 어휘 학습 + TF-IDf 희소행렬로 변환\n",
    "print(features)\n",
    "\n",
    "features = features.toarray() # dense 배열로 변환\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c6d67",
   "metadata": {},
   "source": [
    "CountVectorizer와 비교했을 때 TF-IDF는 자주 나오지만 흔한 단어의 영향은 줄이고, 특정 문서에만 특징적인 단어는 더 강조해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08f18ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amazing' 'and' 'cat' 'do' 'dog' 'is' 'love' 'my' 'think' 'you']\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_vectorizer.get_feature_names_out() # TF-IDF 벡터의 열에 대응하는 토큰 목록\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c21b710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazing</th>\n",
       "      <th>and</th>\n",
       "      <th>cat</th>\n",
       "      <th>do</th>\n",
       "      <th>dog</th>\n",
       "      <th>is</th>\n",
       "      <th>love</th>\n",
       "      <th>my</th>\n",
       "      <th>think</th>\n",
       "      <th>you</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sent1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.606856</td>\n",
       "      <td>0.513275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.737922</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515290</td>\n",
       "      <td>0.435829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491109</td>\n",
       "      <td>0.396224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.553364</td>\n",
       "      <td>0.468032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458054</td>\n",
       "      <td>0.387419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.655957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sent5</th>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.247170</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209054</td>\n",
       "      <td>0.438724</td>\n",
       "      <td>0.353960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        amazing       and       cat        do       dog        is      love  \\\n",
       "sent1  0.000000  0.000000  0.000000  0.000000  0.606856  0.000000  0.606856   \n",
       "sent2  0.000000  0.000000  0.737922  0.000000  0.000000  0.000000  0.515290   \n",
       "sent3  0.000000  0.491109  0.396224  0.000000  0.276682  0.000000  0.553364   \n",
       "sent4  0.000000  0.000000  0.000000  0.000000  0.458054  0.000000  0.458054   \n",
       "sent5  0.438724  0.000000  0.000000  0.438724  0.247170  0.438724  0.000000   \n",
       "\n",
       "             my     think       you  \n",
       "sent1  0.513275  0.000000  0.000000  \n",
       "sent2  0.435829  0.000000  0.000000  \n",
       "sent3  0.468032  0.000000  0.000000  \n",
       "sent4  0.387419  0.000000  0.655957  \n",
       "sent5  0.209054  0.438724  0.353960  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bag of Words\n",
    "sent_df = pd.DataFrame(\n",
    "    features,\n",
    "    columns= feature_names,\n",
    "    index = ['sent1', 'sent2', 'sent3', 'sent4', 'sent5' ]\n",
    ")\n",
    "sent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949067c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.sort_values() missing 1 required positional argument: 'by'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43msent_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: DataFrame.sort_values() missing 1 required positional argument: 'by'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f1ef2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "amazing    0.000000\n",
       "and        0.000000\n",
       "cat        0.737922\n",
       "do         0.000000\n",
       "dog        0.000000\n",
       "is         0.000000\n",
       "love       0.515290\n",
       "my         0.435829\n",
       "think      0.000000\n",
       "you        0.000000\n",
       "Name: sent2, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf-idf 도출과정\n",
    "import numpy as np\n",
    "\n",
    "sent = sent_df.iloc[1] # 두 번째 문장(sent2)의 TF-IDF 벡터 행 추출\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6a60e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29558038919848867\n",
      "0.29558038919848867\n",
      "0.29558038919848867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.57735027, 0.        , 0.        ,\n",
       "       0.        , 0.57735027, 0.57735027, 0.        , 0.        ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I love my cat\n",
    "n_doc_terms = 4  # 이 문서의 총 토큰수 (문서 길이)\n",
    "n_docs = 5 + 1   # 전체 문서 수 (+1은 스무딩 / 분모 안정화)\n",
    "\n",
    "love_tf = 1 / n_doc_terms               # 해당 단어 빈도 +1 / 문서 내 총 토큰 수\n",
    "love_idf = np.log(n_docs / (1 + 4)) + 1 # log(N / (1 + love가 등장한 문서 수) + 1 \n",
    "love_tfidf = love_tf * love_idf         # TF-IDF = TF * IDF\n",
    "print(love_tfidf)\n",
    "\n",
    "my_tf = 1 / n_doc_terms                 # 해당 단어 빈도 +1 / 문서 내 총 토큰 수\n",
    "my_idf = np.log(n_docs / (1 + 4)) + 1   # log(N / (1 + my가 등장한 문서 수) + 1 \n",
    "my_tfidf = my_tf * my_idf               # TF-IDF = TF * IDF\n",
    "print(my_tfidf)\n",
    "\n",
    "cat_tf = 1 / n_doc_terms\n",
    "cat_idf = np.log(n_docs / (1 + 4)) + 1\n",
    "cat_tfidf = cat_tf * cat_idf\n",
    "print(cat_tfidf)\n",
    "\n",
    "# 벡터 정규화\n",
    "sent2_vecs = np.array([0, 0, cat_tfidf, 0, 0, 0, love_tfidf, my_tfidf, 0, 0]) # sent2의 TF-IDF 벡터\n",
    "norm = np.linalg.norm(sent2_vecs) # L2 노름 (벡터의 크기) 계산\n",
    "sent2_vecs = sent2_vecs / norm    # 각 요소를 벡터 전체 크기로 나눠 단위벡터로 정규화\n",
    "sent2_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711be02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I love my dog.</th>\n",
       "      <th>I love my cat.</th>\n",
       "      <th>I love my dog and love my cat.</th>\n",
       "      <th>You love my dog!</th>\n",
       "      <th>Do you think my dog is amazing?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I love my dog.</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.536407</td>\n",
       "      <td>0.743948</td>\n",
       "      <td>0.754798</td>\n",
       "      <td>0.257299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I love my cat.</th>\n",
       "      <td>0.536407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.781507</td>\n",
       "      <td>0.404879</td>\n",
       "      <td>0.091112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I love my dog and love my cat.</th>\n",
       "      <td>0.743948</td>\n",
       "      <td>0.781507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.561530</td>\n",
       "      <td>0.166232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You love my dog!</th>\n",
       "      <td>0.754798</td>\n",
       "      <td>0.404879</td>\n",
       "      <td>0.561530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.426391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Do you think my dog is amazing?</th>\n",
       "      <td>0.257299</td>\n",
       "      <td>0.091112</td>\n",
       "      <td>0.166232</td>\n",
       "      <td>0.426391</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 I love my dog.  I love my cat.  \\\n",
       "I love my dog.                         1.000000        0.536407   \n",
       "I love my cat.                         0.536407        1.000000   \n",
       "I love my dog and love my cat.         0.743948        0.781507   \n",
       "You love my dog!                       0.754798        0.404879   \n",
       "Do you think my dog is amazing?        0.257299        0.091112   \n",
       "\n",
       "                                 I love my dog and love my cat.  \\\n",
       "I love my dog.                                         0.743948   \n",
       "I love my cat.                                         0.781507   \n",
       "I love my dog and love my cat.                         1.000000   \n",
       "You love my dog!                                       0.561530   \n",
       "Do you think my dog is amazing?                        0.166232   \n",
       "\n",
       "                                 You love my dog!  \\\n",
       "I love my dog.                           0.754798   \n",
       "I love my cat.                           0.404879   \n",
       "I love my dog and love my cat.           0.561530   \n",
       "You love my dog!                         1.000000   \n",
       "Do you think my dog is amazing?          0.426391   \n",
       "\n",
       "                                 Do you think my dog is amazing?  \n",
       "I love my dog.                                          0.257299  \n",
       "I love my cat.                                          0.091112  \n",
       "I love my dog and love my cat.                          0.166232  \n",
       "You love my dog!                                        0.426391  \n",
       "Do you think my dog is amazing?                         1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF 기반 문장 유사도 : 코사인 유사도로 문장 간 유사도 행렬 계산\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sent_sim = cosine_similarity(sent_df)\n",
    "sent_sim_df = pd.DataFrame(\n",
    "    sent_sim,             # 데이터는 유사도 결과\n",
    "    columns = sentences,  # 비교 대상 문장 \n",
    "    index = sentences     # 기준 문장\n",
    ")\n",
    "\n",
    "sent_sim_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b871c2",
   "metadata": {},
   "source": [
    "TF-IDF는 BoW보다 흔한 단어의 영향이 줄어, 특징 단어 중심으로 유사도가 계산된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d2767",
   "metadata": {},
   "source": [
    "## 자연어 임베딩(Embedding)이란?\n",
    "\n",
    "자연어 임베딩은 **텍스트(단어/문장/문서)를 고정 길이의 실수 벡터(vector)로 바꾸는 표현 방식**이다.  \n",
    "즉, 컴퓨터가 다룰 수 있도록 **문자를 수치화**하되, 단순 ID가 아니라 **의미·문맥·문법적 특징**이 벡터 공간에 반영되도록 만든다.\n",
    "\n",
    "- 임베딩 덕분에 텍스트끼리 **유사도(코사인 유사도 등)**를 계산할 수 있고  \n",
    "- 머신러닝/딥러닝 모델에 **입력 피처**로 넣을 수 있으며  \n",
    "- “king - man + woman ≈ queen” 같은 **의미 연산**이 벡터 공간에서 가능해진다.\n",
    "\n",
    "---\n",
    "\n",
    "## 임베딩 핵심 정리 표\n",
    "\n",
    "| 구분 | 내용 | 예시/포인트 |\n",
    "|---|---|---|\n",
    "| 정의 | 텍스트를 **고정 길이 실수 벡터**로 변환 | 단어/문장/문서 → `R^d` 벡터 |\n",
    "| 목적 | 컴퓨터가 텍스트를 수치로 처리 + 의미를 보존 | 단순 라벨 인코딩과 다름 |\n",
    "| 표현 대상 | 단어 임베딩 / 문장 임베딩 / 문서 임베딩 | word2vec(단어), SBERT(문장) |\n",
    "| 벡터 의미 | 벡터 공간에서 **거리/각도**가 의미적 유사성을 반영 | 가까울수록 의미가 비슷한 경향 |\n",
    "| 대표 유사도 지표 | 코사인 유사도, 유클리드 거리 | 코사인: 방향(의미) 중심 비교 |\n",
    "| 장점 | 의미적 관계 수치화, 모델 입력 가능, 일반화에 유리 | 검색/추천/분류/클러스터링 등 |\n",
    "| 한계 | 데이터·학습 방식에 따라 편향/품질 차이, OOV 문제 | 학습 코퍼스에 없는 단어 처리 |\n",
    "| 활용 | 분류, 검색, 추천, 군집화, QA, RAG 등 | query↔doc 유사도 계산 |\n",
    "| 학습 방식(큰 분류) | 정적(Static) vs 문맥(Contextual) | 정적: word2vec / 문맥: BERT 계열 |\n",
    "| 정적 임베딩 특징 | 단어당 벡터 1개(문맥 변화 반영 어려움) | “bank” (강둑/은행) 구분 약함 |\n",
    "| 문맥 임베딩 특징 | 같은 단어라도 문맥에 따라 벡터가 달라짐 | “bank”가 문장에 따라 의미 분리 |\n",
    "\n",
    "## 자연어 임베딩 요약\n",
    "\n",
    "- **자연어 임베딩(Embedding)**: 텍스트(단어/문장/문서)를 **고정 길이의 실수 벡터**로 변환하는 기술  \n",
    "- 목적: 컴퓨터가 텍스트를 **수치로 처리**하면서도 **의미/문법 정보**를 벡터에 담게 함  \n",
    "- 효과:\n",
    "  - 벡터 간 **유사도(코사인 유사도 등)** 계산 가능 → 관련도/의미 유사성 비교\n",
    "  - ML/DL 모델의 **입력 피처**로 사용 가능\n",
    "  - 벡터 공간에서 **의미 관계(유추/연산)** 표현 가능(예: king - man + woman ≈ queen)\n",
    "- 종류(큰 분류):\n",
    "  - **정적 임베딩**: 단어당 벡터 1개(문맥 변화 반영 어려움)  \n",
    "  - **문맥 임베딩**: 같은 단어도 문장 문맥에 따라 벡터가 달라짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f72f8c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
