# ==============================================================================
# ğŸš¢ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡í•˜ê¸°: ì¸ê³µì§€ëŠ¥ íƒì • ë†€ì´ ğŸ•µï¸â€â™€ï¸ğŸ•µï¸â€â™‚ï¸
# ==============================================================================

# ì•ˆë…•í•˜ì„¸ìš”! ì˜¤ëŠ˜ì€ ìš°ë¦¬ê°€ íƒì •ì´ ë˜ì–´ì„œ 100ë…„ ì „ ì¹¨ëª°í•œ íƒ€ì´íƒ€ë‹‰ ë°°ì˜ ë¹„ë°€ì„ í’€ì–´ë³¼ ê±°ì˜ˆìš”.
# ì»´í“¨í„°ì—ê²Œ "ëˆ„ê°€ ì‚´ì•„ë‚¨ì•˜ì„ê¹Œ?"ë¥¼ ë§íˆê²Œ ê°€ë¥´ì³ì£¼ëŠ” ë†€ì´ëë‹ˆë‹¤.
# ì•„ì£¼ ì‰¬ìš´ ë§ë¡œ í•˜ë‚˜í•˜ë‚˜ ì„¤ëª…í•´ ì¤„ê²Œìš”. ì¤€ë¹„ëë‚˜ìš”? ì¶œë°œ! ğŸš€

# ------------------------------------------------------------------------------
# 1ë‹¨ê³„: ë„êµ¬ ì±™ê¸°ê¸° (ë„ì„œê´€ì—ì„œ ì±… ë¹Œë ¤ì˜¤ê¸° ğŸ“š)
# ------------------------------------------------------------------------------
# ìš”ë¦¬ì‚¬ê°€ ìš”ë¦¬ë¥¼ í•˜ë ¤ë©´ ì¹¼ì´ë‘ ëƒ„ë¹„ê°€ í•„ìš”í•˜ì£ ?
# ì½”ë”©ì„ í•˜ë ¤ë©´ 'ë¼ì´ë¸ŒëŸ¬ë¦¬'ë¼ëŠ” ë„êµ¬ ìƒìê°€ í•„ìš”í•´ìš”.
# pandas(íŒë‹¤ìŠ¤): í‘œë¥¼ ë‹¤ë£¨ëŠ” ì—‘ì…€ ê°™ì€ ì¹œêµ¬ ğŸ¼
# numpy(ë„˜íŒŒì´): ìˆ«ìë¥¼ ê³„ì‚°í•˜ëŠ” ìˆ˜í•™ ì²œì¬ ì¹œêµ¬ â—
# matplotlib, seaborn: ê·¸ë¦¼ì„ ê·¸ë ¤ì£¼ëŠ” í™”ê°€ ì¹œêµ¬ë“¤ ğŸ¨
# sklearn(ì‚¬ì´í‚·ëŸ°): ì¸ê³µì§€ëŠ¥ ë¡œë´‡ì„ ë§Œë“¤ì–´ì£¼ëŠ” ê³µì¥ ğŸ¤–

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# ê²½ê³  ë©”ì‹œì§€ ë„ê¸° (ì‹œë„ëŸ¬ìš´ ì”ì†Œë¦¬ëŠ” ì ê¹ êº¼ë‘˜ê²Œìš”!)
import warnings
warnings.filterwarnings('ignore')

print("ëª¨ë“  ë„êµ¬ê°€ ì¤€ë¹„ë˜ì—ˆì–´ìš”! ğŸ”§")

# ------------------------------------------------------------------------------
# 2ë‹¨ê³„: ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (íƒì • ìˆ˜ì²© í¼ì¹˜ê¸° ğŸ“–)
# ------------------------------------------------------------------------------
# íƒ€ì´íƒ€ë‹‰ ë°°ì— íƒ”ë˜ ì‚¬ëŒë“¤ì˜ ëª…ë‹¨ì„ ì»´í“¨í„°ì—ê²Œ ë³´ì—¬ì¤„ ê±°ì˜ˆìš”.
# ì´ ëª…ë‹¨ì—ëŠ” ì´ë¦„, ë‚˜ì´, ì„±ë³„, ê·¸ë¦¬ê³  ì‚´ì•„ë‚¨ì•˜ëŠ”ì§€ì— ëŒ€í•œ ì •ë³´ê°€ ì í˜€ ìˆì–´ìš”.
# pd.read_csv()ëŠ” ì—‘ì…€ íŒŒì¼ì„ ì½ì–´ì˜¤ëŠ” ì£¼ë¬¸ì´ì—ìš”.

# 'titanic_df'ëŠ” ìš°ë¦¬ê°€ ë³¼ íƒì • ìˆ˜ì²©ì˜ ì´ë¦„ì´ì—ìš”.
titanic_df = pd.read_csv("./data/titanic_train.csv")

# ìˆ˜ì²©ì˜ ì²« 5ì¤„ë§Œ ì‚´ì§ ì—¿ë³¼ê¹Œìš”? (.head()ëŠ” ë¨¸ë¦¬ ë¶€ë¶„ 5ê°œë§Œ ë³´ì—¬ë‹¬ë¼ëŠ” ëœ»ì´ì—ìš”)
print("\n--- íƒì • ìˆ˜ì²©ì˜ ì²« 5ì¥ ---")
print(titanic_df.head())

# ------------------------------------------------------------------------------
# 3ë‹¨ê³„: ìˆ˜ì²© í›‘ì–´ë³´ê¸° (ì •ë³´ í™•ì¸í•˜ê¸° ğŸ‘€)
# ------------------------------------------------------------------------------
# ìˆ˜ì²©ì— êµ¬ë©(ë¹ˆì¹¸)ì´ ëš«ë ¤ ìˆì§€ëŠ” ì•Šì€ì§€, ìˆ«ìì¸ì§€ ê¸€ìì¸ì§€ í™•ì¸í•´ë´ìš”.
# .info()ëŠ” ìˆ˜ì²©ì˜ ìƒíƒœë¥¼ ì•Œë ¤ì£¼ëŠ” ê±´ê°• ê²€ì§„ ê°™ì€ ê±°ì˜ˆìš”.

print("\n--- ìˆ˜ì²© ê±´ê°• ê²€ì§„ ê²°ê³¼ ---")
titanic_df.info()

# ------------------------------------------------------------------------------
# 4ë‹¨ê³„: ë¹ˆì¹¸ ì±„ìš°ê¸° (ì§€ì›Œì§„ ê¸€ì”¨ ë³µêµ¬í•˜ê¸° âœï¸)
# ------------------------------------------------------------------------------
# íƒì • ìˆ˜ì²©ì„ ë³´ë‹ˆ, ë‚˜ì´(Age)ë‚˜ ë°© ë²ˆí˜¸(Cabin)ë¥¼ ì•ˆ ì ì€ ì‚¬ëŒë“¤ì´ ìˆë„¤ìš”!
# ì»´í“¨í„°ëŠ” ë¹ˆì¹¸(Null)ì´ ìˆìœ¼ë©´ í—·ê°ˆë ¤í•´ì„œ ê³„ì‚°ì„ ëª» í•´ìš”.
# ê·¸ë˜ì„œ ìš°ë¦¬ê°€ ì ë‹¹í•œ ê°’ìœ¼ë¡œ ë¹ˆì¹¸ì„ ë©”ì›Œì¤˜ì•¼ í•´ìš”. ì´ë¥¼ 'ê²°ì¸¡ì¹˜ ì²˜ë¦¬'ë¼ê³  í•´ìš”.

# Age(ë‚˜ì´)ê°€ ë¹„ì–´ìˆëŠ” ì¹¸ì€, ë‚˜ë¨¸ì§€ ì‚¬ëŒë“¤ì˜ 'í‰ê·  ë‚˜ì´'ë¡œ ì±„ì›Œì¤„ê²Œìš”.
titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)

# Cabin(ë°© ë²ˆí˜¸)ê³¼ Embarked(íƒ„ í•­êµ¬)ê°€ ë¹„ì–´ìˆëŠ” ì¹¸ì€ ê·¸ëƒ¥ 'N'ì´ë¼ê³  ì¨ë†“ì„ê²Œìš”.
# 'N'ì€ 'ëª¨ë¦„(Not found)'ì˜ ì•½ìë¼ê³  ìƒê°í•˜ë©´ ë¼ìš”.
titanic_df['Cabin'].fillna('N', inplace=True)
titanic_df['Embarked'].fillna('N', inplace=True)

print("\n--- ë¹ˆì¹¸ ì±„ìš°ê¸° ì™„ë£Œ! ë‚¨ì€ ë¹ˆì¹¸ì´ ìˆëŠ”ì§€ í™•ì¸í•´ë³¼ê¹Œìš”? ---")
print(titanic_df.isnull().sum()) # í•©ê³„ê°€ ëª¨ë‘ 0ì´ë©´ ë¹ˆì¹¸ì´ ì—†ë‹¤ëŠ” ëœ»ì´ì—ìš”!

# ------------------------------------------------------------------------------
# 5ë‹¨ê³„: ë°ì´í„° ìì„¸íˆ ì‚´í´ë³´ê¸° (ë‹ë³´ê¸°ë¡œ ê´€ì°°í•˜ê¸° ğŸ”)
# ------------------------------------------------------------------------------
# ì‚¬ëŒë“¤ì´ ì–´ë–¤ íŠ¹ì§•ì„ ê°€ì§€ê³  ìˆëŠ”ì§€ ê·¸ë¦¼ì„ ê·¸ë ¤ì„œ ì‚´í´ë´ìš”.

# ë‚¨ìì™€ ì—¬ì ì¤‘ ëˆ„ê°€ ë” ë§ì´ ì‚´ì•„ë‚¨ì•˜ì„ê¹Œìš”? ê·¸ë¦¼ì„ ê·¸ë ¤ì„œ ë¹„êµí•´ë´ìš”.
print("\n--- ì„±ë³„ì— ë”°ë¥¸ ìƒì¡´ì ìˆ˜ ê·¸ë¦¬ê¸° ---")
# sns.barplotì€ ë§‰ëŒ€ì‚¬íƒ• ê°™ì€ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ì¤˜ìš”.
# xì¶•ì€ ì„±ë³„(Sex), yì¶•ì€ ìƒì¡´ì—¬ë¶€(Survived)ì˜ˆìš”.
plt.figure()
sns.barplot(x='Sex', y='Survived', data=titanic_df)
plt.title("Sex vs Survived")
plt.show() # ê·¸ë¦¼ì•„ ë‚˜ì™€ë¼ ì–!

# ì´ë²ˆì—ëŠ” ë“±ê¸‰(Pclass)ë³„ë¡œ ëˆ„ê°€ ë§ì´ ì‚´ì•˜ë‚˜ ë³¼ê¹Œìš”? 
# 1ë“±ì„ ë¶€ìë“¤ê³¼ 3ë“±ì„ ì„œë¯¼ë“¤ì˜ ì°¨ì´ë¥¼ ë³´ëŠ” ê±°ì˜ˆìš”.
print("\n--- ì¢Œì„ ë“±ê¸‰ê³¼ ì„±ë³„ì— ë”°ë¥¸ ìƒì¡´ì ìˆ˜ ---")
plt.figure()
sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)
plt.title("Pclass vs Survived")
plt.show()

# ë‚˜ì´ë³„ë¡œë„ í•œë²ˆ ë³¼ê¹Œìš”?
# ì–´ë¦° ì•„ê¸°, ì–´ë¦°ì´, ì–´ë¥¸, ë…¸ì¸ìœ¼ë¡œ ê·¸ë£¹ì„ ë‚˜ëˆ ì„œ ë³¼ê²Œìš”.
def get_category(age):
    cat = ''
    if age <= -1: cat = 'Unknown'       # ì•Œìˆ˜ì—†ìŒ
    elif age <= 5: cat = 'Baby'         # 5ì‚´ ì´í•˜ ì•„ê¸°
    elif age <= 12: cat = 'Child'       # 12ì‚´ ì´í•˜ ì–´ë¦°ì´
    elif age <= 18: cat = 'Teenager'    # 10ëŒ€ ì†Œë…„ì†Œë…€
    elif age <= 25: cat = 'Student'     # í•™ìƒ
    elif age <= 35: cat = 'Young Adult' # ì Šì€ ì–´ë¥¸
    elif age <= 60: cat = 'Adult'       # ì–´ë¥¸
    else : cat = 'Elderly'              # ë…¸ì¸
    return cat

print("\n--- ë‚˜ì´ëŒ€ë³„ ìƒì¡´ì ìˆ˜ ---")
plt.figure(figsize=(10,6))
group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']
# ì•„ê¹Œ ë§Œë“  ê·œì¹™(í•¨ìˆ˜)ì„ ì ìš©í•´ì„œ ìƒˆë¡œìš´ 'Age_cat'ì´ë¼ëŠ” ê·¸ë£¹ì„ ë§Œë“¤ì–´ìš”.
titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))
sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order=group_names)
plt.show()

# ë‹¤ ë´¤ìœ¼ë©´ 'Age_cat'ì€ ì´ì œ í•„ìš” ì—†ìœ¼ë‹ˆ ì§€ìš¸ê²Œìš”.
titanic_df.drop('Age_cat', axis=1, inplace=True)

# ------------------------------------------------------------------------------
# 6ë‹¨ê³„: ì»´í“¨í„°ê°€ ì´í•´í•˜ëŠ” ë§ë¡œ ë°”ê¾¸ê¸° (ë²ˆì—­í•˜ê¸° ğŸ—£ï¸â¡ï¸ğŸ”¢)
# ------------------------------------------------------------------------------
# ì»´í“¨í„°ëŠ” ìˆ«ìë°–ì— ëª¨ë¥´ëŠ” ë°”ë³´ì˜ˆìš”. 'ë‚¨ì', 'ì—¬ì' ê°™ì€ ê¸€ìëŠ” ì´í•´ë¥¼ ëª» í•´ìš”.
# ê·¸ë˜ì„œ ê¸€ìë¥¼ ìˆ«ìë¡œ ë°”ê¿”ì¤˜ì•¼ í•´ìš”. ì´ê±¸ 'ì¸ì½”ë”©(Encoding)'ì´ë¼ê³  í•´ìš”.
# ì•”í˜¸ ë§Œë“¤ê¸°ë‘ ë¹„ìŠ·í•´ìš”! ë‚¨ì=0, ì—¬ì=1 ì²˜ëŸ¼ìš”.

from sklearn.preprocessing import LabelEncoder

def encode_features(dataDF):
    # ë°”ê¿€ ì¹œêµ¬ë“¤ ëª©ë¡: ë°©ë²ˆí˜¸(Cabin), ì„±ë³„(Sex), íƒ„ ê³³(Embarked)
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        # ê¸€ìë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë§ˆë²•ì˜ ë„êµ¬(le)ë¥¼ ì‚¬ìš©í•´ìš”.
        le = le.fit(dataDF[feature])
        dataDF[feature] = le.transform(dataDF[feature])
    return dataDF

# ë°© ë²ˆí˜¸ëŠ” ë„ˆë¬´ ê¸°ë‹ˆê¹Œ, ë§¨ ì• ê¸€ìë§Œ ë”°ì˜¬ê²Œìš”. (C85 -> C)
titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]
titanic_df = encode_features(titanic_df)

print("\n--- ìˆ«ìë¡œ ë³€ì‹ í•œ ìˆ˜ì²©ì˜ ì²« 5ì¤„ ---")
print(titanic_df.head())

# ------------------------------------------------------------------------------
# 7ë‹¨ê³„: í•„ìš” ì—†ëŠ” ì •ë³´ ë²„ë¦¬ê¸° (ì§ ê°€ë³ê²Œ í•˜ê¸° ğŸ—‘ï¸)
# ------------------------------------------------------------------------------
# ìƒì¡´ìë¥¼ ë§íˆëŠ”ë° íƒ‘ìŠ¹ê° ë²ˆí˜¸(PassengerId), ì´ë¦„(Name), í‹°ì¼“ ë²ˆí˜¸(Ticket)ëŠ” ë³„ë¡œ ì•ˆ ì¤‘ìš”í•´ìš”.
# ê°€ë°©ì´ ë¬´ê±°ìš°ë©´ ë‹¬ë¦¬ê¸° í˜ë“œë‹ˆê¹Œ í•„ìš” ì—†ëŠ” ê±´ ë²„ë ¤ìš”.

def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

titanic_df = drop_features(titanic_df)

# ì§€ê¸ˆê¹Œì§€ í•œ 4, 6, 7ë‹¨ê³„ë¥¼ í•œ ë²ˆì— í•´ì£¼ëŠ” ë§ˆë²•ì˜ ì£¼ë¬¸ì„œ(í•¨ìˆ˜)ë¥¼ ë§Œë“¤ì–´ì„œ ì •ë¦¬í•´ë‘˜ê²Œìš”.
def transform_features(df):
    df['Age'].fillna(df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    df['Fare'].fillna(0, inplace=True) # ìš”ê¸ˆ ë¹ˆì¹¸ì€ 0ì›ìœ¼ë¡œ
    
    df['Cabin'] = df['Cabin'].str[:1]
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
            
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

# ------------------------------------------------------------------------------
# 8ë‹¨ê³„: ê³µë¶€í•  ë¬¸ì œì§‘ê³¼ ì •ë‹µì§€ ë‚˜ëˆ„ê¸° (ì‹œí—˜ ì¤€ë¹„ ğŸ“)
# ------------------------------------------------------------------------------
# ì»´í“¨í„° ë¡œë´‡ì—ê²Œ ê³µë¶€ë¥¼ ì‹œí‚¤ë ¤ë©´ ë¬¸ì œ(X)ì™€ ì •ë‹µ(y)ì„ ë”°ë¡œ ì¤˜ì•¼ í•´ìš”.
# ë¬¸ì œ(X): ë‚˜ì´, ì„±ë³„, ë“±ê¸‰ ë“±ë“±...
# ì •ë‹µ(y): ì‚´ì•˜ë‹¤(1) / ì£½ì—ˆë‹¤(0)

# ë‹¤ì‹œ ì²˜ìŒë¶€í„° ë°ì´í„°ë¥¼ ê¹¨ë—í•˜ê²Œ ë¶ˆëŸ¬ì™€ì„œ ì •ë¦¬í• ê²Œìš”.
titanic_df = pd.read_csv("./data/titanic_train.csv")
y_titanic_df = titanic_df['Survived'] # ì •ë‹µì§€ (ìƒì¡´ ì—¬ë¶€)
X_titanic_df = titanic_df.drop('Survived', axis=1) # ë¬¸ì œì§€ (ë‚˜ë¨¸ì§€ ì •ë³´ë“¤)

# ì•„ê¹Œ ë§Œë“  ë§ˆë²•ì˜ ì£¼ë¬¸ì„œë¡œ ë¬¸ì œì§€ë¥¼ ìˆ«ìë¡œ ê¹”ë”í•˜ê²Œ ë°”ê¿”ìš”.
X_titanic_df = transform_features(X_titanic_df)

# ê·¸ë¦¬ê³  [ê³µë¶€ìš© ë¬¸ì œì§‘]ê³¼ [ì‹¤ì „ ì‹œí—˜ì§€]ë¡œ ë‚˜ëˆ ì•¼ í•´ìš”.
# ê³µë¶€ë§Œ í•˜ê³  ë°”ë¡œ ê·¸ ë¬¸ì œë¡œ ì‹œí—˜ ë³´ë©´ 100ì  ë§ê² ì£ ? ê·¸ê±´ ë°˜ì¹™ì´ì—ìš”!
# ê·¸ë˜ì„œ ê³µë¶€ìš©(Train) 80%, ì‹œí—˜ìš©(Test) 20%ë¡œ ìª¼ê°œìš”.

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \
                                                    test_size=0.2, random_state=11)
                                                    # test_size=0.2ëŠ” 20%ë¥¼ ì‹œí—˜ì§€ë¡œ ì“´ë‹¤ëŠ” ëœ»!

# ------------------------------------------------------------------------------
# 9ë‹¨ê³„: ë¡œë´‡ í•™ìƒë“¤ ì…í•™ì‹ (ëª¨ë¸ ë§Œë“¤ê¸° ğŸ‘¨â€ğŸ“ğŸ‘©â€ğŸ“)
# ------------------------------------------------------------------------------
# 3ëª…ì˜ ë‹¤ë¥¸ ì„±ê²©ì„ ê°€ì§„ ë¡œë´‡ í•™ìƒë“¤ì„ ë°ë ¤ì™”ì–´ìš”. ëˆ„ê°€ ê³µë¶€ë¥¼ ì œì¼ ì˜í•˜ë‚˜ ë³¼ê¹Œìš”?

# 1ë²ˆ í•™ìƒ: ê²°ì • íŠ¸ë¦¬ (ìŠ¤ë¬´ê³ ê°œ ë¡œë´‡) ğŸŒ³
# "ë‚¨ìì•¼? (ë„¤/ì•„ë‹ˆì˜¤)", "ë‚˜ì´ê°€ ë§ì•„? (ë„¤/ì•„ë‹ˆì˜¤)" ì´ë ‡ê²Œ ì§ˆë¬¸í•˜ë©´ì„œ ë‹µì„ ì°¾ì•„ìš”.
from sklearn.tree import DecisionTreeClassifier
dt_clf = DecisionTreeClassifier(random_state=11)

# 2ë²ˆ í•™ìƒ: ëœë¤ í¬ë ˆìŠ¤íŠ¸ (ìˆ²ì†ì˜ ë‹¤ìˆ˜ê²° ë¡œë´‡) ğŸŒ²ğŸŒ²ğŸŒ²
# 1ë²ˆ ê°™ì€ ë‚˜ë¬´ ë¡œë´‡ ì—¬ëŸ¬ ëª…ì´ ëª¨ì—¬ì„œ íˆ¬í‘œë¡œ ì •ë‹µì„ ì •í•´ìš”. 
# í˜¼ì ê²°ì •í•˜ëŠ” ê²ƒë³´ë‹¤ ì¹œêµ¬ë“¤ê³¼ ì˜ë…¼í•˜ë©´ ë” ë˜‘ë˜‘í•˜ê² ì£ ?
from sklearn.ensemble import RandomForestClassifier
rf_clf = RandomForestClassifier(random_state=11)

# 3ë²ˆ í•™ìƒ: ë¡œì§€ìŠ¤í‹± íšŒê·€ (ì„  ê¸‹ê¸° ë¡œë´‡) ğŸ“
# ë°ì´í„°ë“¤ ì‚¬ì´ì— ì„ ì„ ì´¥! ê·¸ì–´ì„œ ì´ìª½ì€ ìƒì¡´, ì €ìª½ì€ ì‚¬ë§! ì´ë ‡ê²Œ ë‚˜ëˆ ìš”.
from sklearn.linear_model import LogisticRegression
lr_clf = LogisticRegression(solver='liblinear')

from sklearn.metrics import accuracy_score # ì±„ì ê¸° (ì–¼ë§ˆë‚˜ ë§í˜”ë‚˜?)

# ------------------------------------------------------------------------------
# 10ë‹¨ê³„: ê³µë¶€í•˜ê³  ì‹œí—˜ë³´ê¸° (í•™ìŠµ ë° í‰ê°€ ğŸ’¯)
# ------------------------------------------------------------------------------
# ì´ì œ ë¡œë´‡ë“¤ì—ê²Œ "ì, ê³µë¶€ìš© ë¬¸ì œì§‘(X_train)ì´ë‘ ì •ë‹µ(y_train)ì„ ì¤„ í…Œë‹ˆ ê³µë¶€í•´ë¼!" í•˜ê³  ì‹œí‚µë‹ˆë‹¤. (.fit)
# ê·¸ë¦¬ê³  "ì‹œí—˜ì§€(X_test) í’€ì–´ë´!" í•˜ê³  ì‹œí‚µë‹ˆë‹¤. (.predict)
# ë§ˆì§€ë§‰ìœ¼ë¡œ ì±„ì ê¸°(accuracy_score)ë¡œ ì ìˆ˜ë¥¼ ë§¤ê²¨ìš”.

# 1ë²ˆ í•™ìƒ (ê²°ì • íŠ¸ë¦¬)
dt_clf.fit(X_train, y_train)
dt_pred = dt_clf.predict(X_test)
print(f'ê²°ì • íŠ¸ë¦¬ ë¡œë´‡ì˜ ì ìˆ˜: {accuracy_score(y_test, dt_pred):.4f}')

# 2ë²ˆ í•™ìƒ (ëœë¤ í¬ë ˆìŠ¤íŠ¸)
rf_clf.fit(X_train, y_train)
rf_pred = rf_clf.predict(X_test)
print(f'ëœë¤ í¬ë ˆìŠ¤íŠ¸ ë¡œë´‡ì˜ ì ìˆ˜: {accuracy_score(y_test, rf_pred):.4f}')

# 3ë²ˆ í•™ìƒ (ë¡œì§€ìŠ¤í‹± íšŒê·€)
lr_clf.fit(X_train, y_train)
lr_pred = lr_clf.predict(X_test)
print(f'ë¡œì§€ìŠ¤í‹± íšŒê·€ ë¡œë´‡ì˜ ì ìˆ˜: {accuracy_score(y_test, lr_pred):.4f}')

# ------------------------------------------------------------------------------
# 11ë‹¨ê³„: ëª¨ì˜ê³ ì‚¬ ì—¬ëŸ¬ ë²ˆ ë³´ê¸° (êµì°¨ ê²€ì¦ K-Fold ğŸ”„)
# ------------------------------------------------------------------------------
# í•œ ë²ˆë§Œ ì‹œí—˜ ë³´ë©´ ìš´ì´ ì¢‹ì•„ì„œ ì˜ ë´¤ì„ ìˆ˜ë„ ìˆì–ì•„ìš”?
# ê·¸ë˜ì„œ 5ë²ˆì˜ ëª¨ì˜ê³ ì‚¬ë¥¼ ë´ì„œ ì§„ì§œ ì‹¤ë ¥ì„ ì•Œì•„ë³¼ê²Œìš”.
# ë¬¸ì œì§‘ì„ 5ë“±ë¶„í•´ì„œ ëŒì•„ê°€ë©´ì„œ 4ê°œëŠ” ê³µë¶€í•˜ê³ , 1ê°œëŠ” ì‹œí—˜ ë³´ëŠ” ë°©ì‹ì´ì—ìš”.

from sklearn.model_selection import KFold

def exec_kfold(clf, folds=5):
    kfold = KFold(n_splits=folds) # 5ë“±ë¶„ í•˜ëŠ” ì¹¼
    scores = []
    
    # 5ë²ˆ ë°˜ë³µí•˜ë©´ì„œ ì‹œí—˜ ë³´ê¸°
    for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):
        # ë¬¸ì œì§‘ ìë¥´ê¸°
        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]
        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]
        
        # ê³µë¶€í•˜ê³  ì‹œí—˜ë³´ê¸°
        clf.fit(X_train, y_train)
        predictions = clf.predict(X_test)
        
        # ì ìˆ˜ ë§¤ê¸°ê¸°
        accuracy = accuracy_score(y_test, predictions)
        scores.append(accuracy)
        print(f"ëª¨ì˜ê³ ì‚¬ {iter_count}íšŒ ì ìˆ˜: {accuracy:.4f}")
    
    # í‰ê·  ì ìˆ˜
    print(f"## í‰ê·  ì ìˆ˜: {np.mean(scores):.4f}")

print("\n--- ê²°ì • íŠ¸ë¦¬ ë¡œë´‡ì˜ ëª¨ì˜ê³ ì‚¬ ê²°ê³¼ ---")
exec_kfold(dt_clf, folds=5)

# cross_val_scoreë¼ëŠ” ë„êµ¬ë¥¼ ì“°ë©´ ìœ„ ê³¼ì •ì„ í•œ ë°©ì— í•´ì¤˜ìš”!
from sklearn.model_selection import cross_val_score

print("\n--- ìë™ ëª¨ì˜ê³ ì‚¬ ë„êµ¬ ì‚¬ìš© ê²°ê³¼ ---")
scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)
for iter_count, accuracy in enumerate(scores):
    print(f"ëª¨ì˜ê³ ì‚¬ {iter_count}íšŒ ì ìˆ˜: {accuracy:.4f}")
print(f"## í‰ê·  ì ìˆ˜: {np.mean(scores):.4f}")

# ------------------------------------------------------------------------------
# 12ë‹¨ê³„: ìµœì ì˜ ì¥ë¹„ ë§ì¶°ì£¼ê¸° (í•˜ì´í¼ íŒŒë¼ë¯¸í„° íŠœë‹ âš™ï¸)
# ------------------------------------------------------------------------------
# ë¡œë´‡ì´ ë” ë˜‘ë˜‘í•´ì§€ê²Œ "ì•ˆê²½ì„ ì”Œì›Œì¤„ê¹Œ?", "ë³´ì²­ê¸°ë¥¼ ê»´ì¤„ê¹Œ?" ê³ ë¯¼í•˜ëŠ” ë‹¨ê³„ì˜ˆìš”.
# ê²°ì • íŠ¸ë¦¬ ë¡œë´‡ì˜ 'ë‚˜ë¬´ ê¹Šì´(max_depth)' ë“±ì„ ì¡°ì ˆí•´ì£¼ë©´ ì„±ëŠ¥ì´ ë‹¬ë¼ì ¸ìš”.
# GridSearchCVëŠ” "ëª¨ë“  ê²½ìš°ì˜ ìˆ˜ë¥¼ ë‹¤ ì‹¤í—˜í•´ë³´ê³  ì œì¼ ì¢‹ì€ ê±¸ ê³¨ë¼ì¤˜!" í•˜ëŠ” ë„êµ¬ì˜ˆìš”.

from sklearn.model_selection import GridSearchCV

# ì‹¤í—˜í•´ë³¼ ëª©ë¡ (ì•ˆê²½, ëª¨ì, ì‹ ë°œ...)
parameters = {
    'max_depth': [2, 3, 5, 10],            # ë‚˜ë¬´ì˜ ê¹Šì´ (ë„ˆë¬´ ê¹Šìœ¼ë©´ ë³µì¡í•´ì ¸ìš”)
    'min_samples_split': [2, 3, 5],        # ê°€ì§€ì¹˜ê¸°í•  ìµœì†Œ ì¡°ê±´
    'min_samples_leaf': [1, 5, 8]          # ìì‚¬ê·€ì— ë‚¨ì•„ì•¼ í•  ìµœì†Œ ê°œìˆ˜
}

# 5ë²ˆì”© ëª¨ì˜ê³ ì‚¬ ë³´ë©´ì„œ ì œì¼ ì¢‹ì€ ì¥ë¹„ ì°¾ê¸°
# refit=TrueëŠ” "ì œì¼ ì¢‹ì€ ì¥ë¹„ ì°¾ìœ¼ë©´ ê·¸ê±¸ë¡œ ë¡œë´‡ì„ ì™„ì „íˆ ë¬´ì¥ì‹œì¼œì¤˜" ë¼ëŠ” ëœ»ì´ì—ìš”.
grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', cv=5, refit=True)

# ì‹¤í—˜ ì‹œì‘!
grid_dclf.fit(X_train, y_train) # ì£¼ì˜: ì—¬ê¸°ì„œëŠ” ë‹¤ì‹œ ë§¨ ì²˜ìŒ ë‚˜ëˆ´ë˜ 8:2ì˜ X_trainì„ ì¨ìš”.

print("\n--- ìµœê³ ì˜ ì¥ë¹„ ì°¾ê¸° ê²°ê³¼ ---")
print('ê°€ì¥ ì¢‹ì€ ì¥ë¹„ ëª©ë¡:', grid_dclf.best_params_)
print(f'ê·¸ë•Œì˜ ìµœê³  ì ìˆ˜: {grid_dclf.best_score_:.4f}')

# ì°¾ì€ ìµœê³ ì˜ ì¥ë¹„ë¡œ ë¬´ì¥í•œ ë¡œë´‡ êº¼ë‚´ê¸°
best_dclf = grid_dclf.best_estimator_

# ì „ì„¤ì˜ ì•„ì´í…œì„ ì¥ì°©í•œ ë¡œë´‡ìœ¼ë¡œ ë§ˆì§€ë§‰ ì§„ì§œ ì‹œí—˜ ë³´ê¸°
dpredictions = best_dclf.predict(X_test)
accuracy = accuracy_score(y_test, dpredictions)
print(f'ìµœì¢… ì—…ê·¸ë ˆì´ë“œëœ ê²°ì • íŠ¸ë¦¬ ë¡œë´‡ì˜ ì ìˆ˜: {accuracy:.4f}')

# ==============================================================================
# ë! ğŸ‰
# ì™€! ìš°ë¦¬ê°€ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ìë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë©‹ì§„ ì¸ê³µì§€ëŠ¥ì„ ë§Œë“¤ì—ˆì–´ìš”!
# ì²˜ìŒì—” ê·¸ëƒ¥ ìˆ«ì ë©ì–´ë¦¬ì˜€ëŠ”ë°, ì´ì œëŠ” ëˆ„ê°€ ì‚´ì§€ ì£½ì„ì§€ ë§íˆëŠ” ë˜‘ë˜‘í•œ ë¡œë´‡ì´ ë˜ì—ˆë„¤ìš”.
# ì •ë§ ê³ ìƒ ë§ì•˜ì–´ìš”! ğŸ‘ğŸ‘ğŸ‘
# ==============================================================================
