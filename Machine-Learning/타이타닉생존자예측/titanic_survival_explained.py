# ==============================================================================
# ğŸš¢ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡í•˜ê¸°: ì¸ê³µì§€ëŠ¥ íƒì • ë†€ì´ (ì™„ì „íŒ) ğŸ•µï¸â€â™€ï¸ğŸ•µï¸â€â™‚ï¸
# ==============================================================================

# ì•ˆë…•í•˜ì„¸ìš”! ì•„ê¹Œë³´ë‹¤ ë” ìì„¸í•˜ê²Œ íƒì • ë†€ì´ë¥¼ í•´ë³¼ ê±°ì˜ˆìš”.
# ìˆ˜ì²©ì˜ ì‘ì€ ë‚™ì„œ í•˜ë‚˜í•˜ë‚˜ ë†“ì¹˜ì§€ ì•Šê³  ê¼¼ê¼¼í•˜ê²Œ ì‚´í´ë³¼ê²Œìš”!

# ------------------------------------------------------------------------------
# 1ë‹¨ê³„: ë„êµ¬ ì±™ê¸°ê¸° & ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ğŸ“š
# ------------------------------------------------------------------------------
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

# ì—‘ì…€ íŒŒì¼(csv)ì„ ì½ì–´ì„œ 'titanic_df'ë¼ëŠ” íƒì • ìˆ˜ì²©ì— ì˜®ê²¨ ì ì–´ìš”.
titanic_df = pd.read_csv("./data/titanic_train.csv")

print("--- 1. íƒì • ìˆ˜ì²©ì˜ ì²« 5ì¤„ ---")
print(titanic_df.head())

# ------------------------------------------------------------------------------
# 2ë‹¨ê³„: ìˆ˜ì²© í›‘ì–´ë³´ê¸° (ì •ë³´ í™•ì¸) ğŸ‘€
# ------------------------------------------------------------------------------
# ë°ì´í„°ê°€ ëª‡ ê°œì¸ì§€, ë¹ˆì¹¸ì€ ì—†ëŠ”ì§€ í™•ì¸í•´ìš”.
print("\n--- 2. ìˆ˜ì²© ê±´ê°• ê²€ì§„ (ì •ë³´ í™•ì¸) ---")
titanic_df.info()

# ë¹ˆì¹¸(Null)ì´ ëª‡ ê°œì¸ì§€ ì„¸ì–´ë³¼ê¹Œìš”?
print("\n--- 3. ë¹„ì–´ìˆëŠ” ì¹¸ ê°œìˆ˜ ì„¸ì–´ë³´ê¸° ---")
print(titanic_df.isnull().sum())

# ------------------------------------------------------------------------------
# 3ë‹¨ê³„: ë¹ˆì¹¸ ì±„ìš°ê¸° (ê²°ì¸¡ì¹˜ ì²˜ë¦¬) âœï¸
# ------------------------------------------------------------------------------
# ë‚˜ì´(Age)ëŠ” í‰ê·  ë‚˜ì´ë¡œ, ë‚˜ë¨¸ì§€ëŠ” 'N'ìœ¼ë¡œ ì±„ì›Œì¤„ê²Œìš”.
titanic_df['Age'].fillna(titanic_df['Age'].mean(), inplace=True)
titanic_df['Cabin'].fillna('N', inplace=True)
titanic_df['Embarked'].fillna('N', inplace=True)

print("\n--- 4. ë¹ˆì¹¸ ì±„ìš°ê¸° ì™„ë£Œ! í™•ì¸í•´ë³¼ê¹Œìš”? ---")
print(titanic_df.isnull().sum())

# ------------------------------------------------------------------------------
# 4ë‹¨ê³„: ë°ì´í„° ê¼¼ê¼¼íˆ ëœ¯ì–´ë³´ê¸° (ê°’ ë¶„í¬ í™•ì¸) ğŸ” [ì¶”ê°€ëœ ë‚´ìš©!]
# ------------------------------------------------------------------------------
# ì„±ë³„, ë°© ë²ˆí˜¸, íƒ„ í•­êµ¬ì— ì–´ë–¤ ê°’ë“¤ì´ ìˆëŠ”ì§€ ì„¸ì–´ë´ìš”.
# ë‚¨ì/ì—¬ìëŠ” ëª‡ ëª…ì¸ì§€, ë°© ë²ˆí˜¸ëŠ” ì–´ë–¤ ê²Œ ë§ì€ì§€ ë³´ëŠ” ê±°ì˜ˆìš”.

print("\n--- 5. ì„±ë³„(Sex) ë¶„í¬ í™•ì¸ ---")
print(titanic_df['Sex'].value_counts())

print("\n--- 6. ë°© ë²ˆí˜¸(Cabin) ë¶„í¬ í™•ì¸ ---")
print(titanic_df['Cabin'].value_counts())

print("\n--- 7. íƒ„ í•­êµ¬(Embarked) ë¶„í¬ í™•ì¸ ---")
print(titanic_df['Embarked'].value_counts())

# ë°© ë²ˆí˜¸(Cabin)ê°€ 'C85', 'C123' ì²˜ëŸ¼ ë„ˆë¬´ ë³µì¡í•´ìš”.
# ë§¨ ì• ê¸€ì(C)ê°€ ì¤‘ìš”í•˜ë‹ˆê¹Œ ì• ê¸€ìë§Œ ë‚¨ê¸¸ê²Œìš”.
titanic_df['Cabin'] = titanic_df['Cabin'].str[:1]
print("\n--- 8. ë°© ë²ˆí˜¸ ì• ê¸€ìë§Œ ë‚¨ê¸°ê¸° ---")
print(titanic_df['Cabin'].head())

# ------------------------------------------------------------------------------
# 5ë‹¨ê³„: ëˆ„ê°€ ë” ë§ì´ ì‚´ì•˜ì„ê¹Œ? (ê·¸ë£¹ë³„ ìƒì¡´ì) ğŸ“Š [ì¶”ê°€ëœ ë‚´ìš©!]
# ------------------------------------------------------------------------------
# ì„±ë³„ì— ë”°ë¼ ì‚´ì•˜ëŠ”ì§€(Survived)ë¥¼ ë¬¶ì–´ì„œ(groupby) ì„¸ì–´ë³¼ê¹Œìš”?
# ë‚¨ì(male)ì™€ ì—¬ì(female) ì¤‘ ëˆ„ê°€ ë” ë§ì´ 1(ìƒì¡´)ì´ ë˜ì—ˆì„ê¹Œìš”?

print("\n--- 9. ì„±ë³„ ë³„ ìƒì¡´ì ìˆ˜ ì„¸ì–´ë³´ê¸° ---")
print(titanic_df.groupby(['Sex','Survived'])['Survived'].count())

# ------------------------------------------------------------------------------
# 6ë‹¨ê³„: ê·¸ë¦¼ìœ¼ë¡œ ê·¸ë ¤ë³´ê¸° (ì‹œê°í™”) ğŸ¨
# ------------------------------------------------------------------------------
# ìˆ«ìë¡œë§Œ ë³´ë©´ ë¨¸ë¦¬ ì•„í”„ë‹ˆê¹Œ ê·¸ë¦¼ìœ¼ë¡œ ê·¸ë ¤ë´ìš”.

print("\n--- 10. ê·¸ë˜í”„ ê·¸ë¦¬ê¸° (ì°½ì´ ëœ¨ë©´ ë‹«ì•„ì£¼ì„¸ìš”) ---")

# 1. ì„±ë³„ì— ë”°ë¥¸ ìƒì¡´ í™•ë¥ 
plt.figure()
sns.barplot(x='Sex', y='Survived', data=titanic_df)
plt.title("Sex vs Survived")
plt.show()

# 2. ì¢Œì„ ë“±ê¸‰(Pclass)ê³¼ ì„±ë³„ì— ë”°ë¥¸ ìƒì¡´ í™•ë¥ 
# ë¶€ì(1ë“±ì„)ì™€ ì„œë¯¼(3ë“±ì„)ì˜ ì°¨ì´ë¥¼ ë´ìš”.
plt.figure()
sns.barplot(x='Pclass', y='Survived', hue='Sex', data=titanic_df)
plt.title("Pclass vs Survived")
plt.show()

# 3. ë‚˜ì´(Age)ë³„ ìƒì¡´ í™•ë¥ 
# ë‚˜ì´ë¥¼ êµ¬ë¶„í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë§Œë“¤ì–´ì„œ ê·¸ë˜í”„ë¥¼ ê·¸ë ¤ìš”.
def get_category(age):
    cat = ''
    if age <= -1: cat = 'Unknown'
    elif age <= 5: cat = 'Baby'
    elif age <= 12: cat = 'Child'
    elif age <= 18: cat = 'Teenager'
    elif age <= 25: cat = 'Student'
    elif age <= 35: cat = 'Young Adult'
    elif age <= 60: cat = 'Adult'
    else : cat = 'Elderly'
    return cat

plt.figure(figsize=(10,6))
group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Elderly']
titanic_df['Age_cat'] = titanic_df['Age'].apply(lambda x : get_category(x))
sns.barplot(x='Age_cat', y='Survived', hue='Sex', data=titanic_df, order=group_names)
plt.title("Age vs Survived")
plt.show()

# ë‹¤ ì“´ ì„ì‹œ ì •ë³´ëŠ” ì§€ì›Œìš”.
titanic_df.drop('Age_cat', axis=1, inplace=True)

# ------------------------------------------------------------------------------
# 7ë‹¨ê³„: ì²™ì²™ë°•ì‚¬ í•¨ìˆ˜ ë§Œë“¤ê¸° (ì „ì²˜ë¦¬ í•¨ìˆ˜ ëª¨ìŒ) ğŸ¤– [ì¤‘ìš”!]
# ------------------------------------------------------------------------------
# ì§€ê¸ˆê¹Œì§€ í–ˆë˜ ì •ë¦¬ ì‘ì—…ë“¤ì„ ì–¸ì œë“ ì§€ ë‹¤ì‹œ í•  ìˆ˜ ìˆê²Œ ë¡œë´‡(í•¨ìˆ˜)ìœ¼ë¡œ ë§Œë“¤ì–´ë‘˜ê²Œìš”.

from sklearn.preprocessing import LabelEncoder

# 1. ë¹ˆì¹¸ ì±„ì›Œì£¼ëŠ” ë¡œë´‡
def fillna(df):
    df['Age'].fillna(df['Age'].mean(), inplace=True)
    df['Cabin'].fillna('N', inplace=True)
    df['Embarked'].fillna('N', inplace=True)
    df['Fare'].fillna(0, inplace=True)
    return df

# 2. í•„ìš” ì—†ëŠ” ì •ë³´ ë²„ë¦¬ëŠ” ë¡œë´‡
def drop_features(df):
    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)
    return df

# 3. ê¸€ìë¥¼ ìˆ«ìë¡œ ë°”ê¿”ì£¼ëŠ” ë¡œë´‡ (ì¸ì½”ë”©)
def label_encode(df):
    df['Cabin'] = df['Cabin'].str[:1] # ë°© ë²ˆí˜¸ ì•ê¸€ìë§Œ
    features = ['Cabin', 'Sex', 'Embarked']
    for feature in features:
        le = LabelEncoder()
        le = le.fit(df[feature])
        df[feature] = le.transform(df[feature])
    return df

# 4. ìœ„ 3ë‹¨ê³„ë¥¼ í•œ ë²ˆì— í•´ì£¼ëŠ” ëŒ€ì¥ ë¡œë´‡
def transform_features(df):
    df = fillna(df)
    df = drop_features(df)
    df = label_encode(df)
    return df

# ------------------------------------------------------------------------------
# 8ë‹¨ê³„: ì‹œí—˜ ì¤€ë¹„í•˜ê¸° (ë°ì´í„° ë‚˜ëˆ„ê¸°) ğŸ“
# ------------------------------------------------------------------------------
# ë‹¤ì‹œ ë°ì´í„°ë¥¼ ì²˜ìŒë¶€í„° ë¶ˆëŸ¬ì™€ì„œ ëŒ€ì¥ ë¡œë´‡ì—ê²Œ ë§¡ê¸¸ê²Œìš”.
titanic_df = pd.read_csv("./data/titanic_train.csv")
y_titanic_df = titanic_df['Survived'] # ì •ë‹µ (ìƒì¡´ ì—¬ë¶€)
X_titanic_df = titanic_df.drop('Survived', axis=1) # ë¬¸ì œ (ë‚˜ë¨¸ì§€ ì •ë³´)

# ëŒ€ì¥ ë¡œë´‡ ì¶œë™! ë°ì´í„°ë¥¼ ìˆ«ìë¡œ ì˜ˆì˜ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
X_titanic_df = transform_features(X_titanic_df)

# ê³µë¶€ìš©(Train)ê³¼ ì‹œí—˜ìš©(Test)ìœ¼ë¡œ ë‚˜ëˆ ìš” (8:2 ë¹„ìœ¨)
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_titanic_df, y_titanic_df, \
                                                    test_size=0.2, random_state=11)

# ë°ì´í„°ê°€ ì˜ ë‚˜ëˆ ì¡ŒëŠ”ì§€ ê°œìˆ˜ë¥¼ í™•ì¸í•´ë´ìš”. [ì¶”ê°€ëœ ë‚´ìš©!]
print("\n--- 11. ë°ì´í„° ë‚˜ëˆ„ê¸° í™•ì¸ ---")
print(f"ê³µë¶€í•  ë¬¸ì œ ê°œìˆ˜: {len(X_train)}")
print(f"ì‹œí—˜ë³¼ ë¬¸ì œ ê°œìˆ˜: {len(X_test)}")
print(f"ê³µë¶€í•  ì •ë‹µ ê°œìˆ˜: {len(y_train)}")
print(f"ì‹œí—˜ë³¼ ì •ë‹µ ê°œìˆ˜: {len(y_test)}")

# ------------------------------------------------------------------------------
# 9ë‹¨ê³„: ë¡œë´‡ í•™ìƒë“¤ ê³µë¶€ì‹œí‚¤ê¸° (ëª¨ë¸ í•™ìŠµ) ğŸ«
# ------------------------------------------------------------------------------
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# 3ëª…ì˜ í•™ìƒ ì…ì¥!
dt_clf = DecisionTreeClassifier(random_state=11)
rf_clf = RandomForestClassifier(random_state=11)
lr_clf = LogisticRegression(solver='liblinear')

print("\n--- 12. ë¡œë´‡ í•™ìƒ ì‹œí—˜ ì ìˆ˜ ë°œí‘œ ---")

# 1ë²ˆ: ê²°ì • íŠ¸ë¦¬ í•™ìƒ
dt_clf.fit(X_train, y_train) # ê³µë¶€í•˜ê¸°
dt_pred = dt_clf.predict(X_test) # ì‹œí—˜ë³´ê¸°
print(f'DecisionTreeClassifier(ê²°ì • íŠ¸ë¦¬) ì •í™•ë„: {accuracy_score(y_test, dt_pred):.4f}')

# 2ë²ˆ: ëœë¤ í¬ë ˆìŠ¤íŠ¸ í•™ìƒ
rf_clf.fit(X_train, y_train)
rf_pred = rf_clf.predict(X_test)
print(f'RandomForestClassifier(ëœë¤ í¬ë ˆìŠ¤íŠ¸) ì •í™•ë„: {accuracy_score(y_test, rf_pred):.4f}')

# 3ë²ˆ: ë¡œì§€ìŠ¤í‹± íšŒê·€ í•™ìƒ
lr_clf.fit(X_train, y_train)
lr_pred = lr_clf.predict(X_test)
print(f'LogisticRegression(ë¡œì§€ìŠ¤í‹± íšŒê·€) ì •í™•ë„: {accuracy_score(y_test, lr_pred):.4f}')

# ------------------------------------------------------------------------------
# 10ë‹¨ê³„: ëª¨ì˜ê³ ì‚¬ 5ë²ˆ ë³´ê¸° (K-Fold êµì°¨ ê²€ì¦) ğŸ”„
# ------------------------------------------------------------------------------
from sklearn.model_selection import KFold

def exec_kfold(clf, folds=5):
    kfold = KFold(n_splits=folds)
    scores = []
    
    for iter_count, (train_index, test_index) in enumerate(kfold.split(X_titanic_df)):
        X_train, X_test = X_titanic_df.values[train_index], X_titanic_df.values[test_index]
        y_train, y_test = y_titanic_df.values[train_index], y_titanic_df.values[test_index]
        
        clf.fit(X_train, y_train)
        predictions = clf.predict(X_test)
        accuracy = accuracy_score(y_test, predictions)
        scores.append(accuracy)
        print(f"êµì°¨ ê²€ì¦ {iter_count}ì˜ ì •í™•ë„: {accuracy:.4f}")
    
    print(f"## í‰ê·  ì •í™•ë„: {np.mean(scores):.4f}")

print("\n--- 13. [ê²°ì • íŠ¸ë¦¬] ëª¨ì˜ê³ ì‚¬(K-Fold) ê²°ê³¼ ---")
exec_kfold(dt_clf, folds=5)

# ------------------------------------------------------------------------------
# 11ë‹¨ê³„: ìë™ ëª¨ì˜ê³ ì‚¬ (cross_val_score) â©
# ------------------------------------------------------------------------------
from sklearn.model_selection import cross_val_score

print("\n--- 14. [ê²°ì • íŠ¸ë¦¬] ìë™ ëª¨ì˜ê³ ì‚¬(cross_val_score) ê²°ê³¼ ---")
scores = cross_val_score(dt_clf, X_titanic_df, y_titanic_df, cv=5)
for iter_count, accuracy in enumerate(scores):
    print(f"êµì°¨ ê²€ì¦ {iter_count}ì˜ ì •í™•ë„: {accuracy:.4f}")

print(f"## í‰ê·  ì •í™•ë„: {np.mean(scores):.4f}")

# ------------------------------------------------------------------------------
# 12ë‹¨ê³„: ìµœê³ ì˜ ì•„ì´í…œ ì°¾ê¸° (GridSearchCV) ğŸ’
# ------------------------------------------------------------------------------
from sklearn.model_selection import GridSearchCV

parameters = {
    'max_depth': [2, 3, 5, 10],
    'min_samples_split': [2, 3, 5],
    'min_samples_leaf': [1, 5, 8]
}

# 5ë²ˆì”© ì‹œí—˜ ë³´ë©´ì„œ(cv=5) ì œì¼ ì¢‹ì€ ì„¤ì •ì„ ì°¾ì•„ë¼!
grid_dclf = GridSearchCV(dt_clf, param_grid=parameters, scoring='accuracy', cv=5, refit=True)
grid_dclf.fit(X_train, y_train)

print("\n--- 15. ìµœê³ ì˜ ì•„ì´í…œ ì°¾ê¸° ê²°ê³¼ ---")
print('GridSearchCV ìµœì  í•˜ì´í¼ íŒŒë¼ë¯¸í„°:', grid_dclf.best_params_)
print(f'GridSearchCV ìµœê³  ì •í™•ë„: {grid_dclf.best_score_:.4f}')

# ìµœì ì˜ ì„¤ì •ìœ¼ë¡œ ë§ˆì§€ë§‰ ì‹œí—˜ì„ ë´ë³¼ê¹Œìš”?
best_dclf = grid_dclf.best_estimator_
dpredictions = best_dclf.predict(X_test)
accuracy = accuracy_score(y_test, dpredictions)
print(f'ìµœì¢… ì—…ê·¸ë ˆì´ë“œëœ DecisionTreeClassifier ì •í™•ë„: {accuracy:.4f}')

# ==============================================================================
# ë¯¸ì…˜ ì„±ê³µ! ğŸ‰
# ì•„ê¹Œ ë†“ì³¤ë˜ ë°ì´í„° í™•ì¸(value_counts)ê³¼ ê·¸ë£¹ë³„ ë¹„êµ(groupby)ê¹Œì§€ 
# ëª¨ë‘ í¬í•¨í•´ì„œ ì™„ë²½í•˜ê²Œ ë¶„ì„í–ˆì–´ìš”. ìˆ˜ê³ í–ˆì–´ìš”! ğŸ‘
# ==============================================================================
